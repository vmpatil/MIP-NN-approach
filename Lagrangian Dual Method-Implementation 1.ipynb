{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3c46fe",
   "metadata": {},
   "source": [
    "_Last Updated: 06/10/2021_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ca1facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB, abs_\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55863e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,0],[0,1], [1,0], [1,1]])\n",
    "y = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ab4cc",
   "metadata": {},
   "source": [
    "### Langrangian Dual Subproblems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7e2a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = y.shape[0]\n",
    "D = x[0].shape[0]\n",
    "K = 2 # Number of units in each hidden layer\n",
    "L = 3 # Number of hidden layers\n",
    "\n",
    "w_ub, w_lb, b_ub, b_lb = [1,-1,1,-1]\n",
    "epsilon = 0.01\n",
    "reg_factor1 = 0.1\n",
    "reg_factor2 = 0.1\n",
    "reg_factor3 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "350949fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_0(λ):\n",
    "    \n",
    "    D = x[0].shape[0] # dimension of data\n",
    "\n",
    "    # Create a new model\n",
    "    m = gp.Model(\"0-th layer\")\n",
    "    \n",
    "    # Create variables\n",
    "    \n",
    "    alpha = {}\n",
    "    abs_alpha = {}\n",
    "    beta = {}\n",
    "    h = {}\n",
    "\n",
    "    for k in range(K):\n",
    "        beta[(k,0)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((k,0)))\n",
    "        for d in range(D):\n",
    "            alpha[(d,k,0)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((d,k,0)))\n",
    "            abs_alpha[(d,k,0)] = m.addVar(lb=0, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"abs_alpha\"+str((d,k,0)))\n",
    "            \n",
    "        for n in range(N):\n",
    "            h[(n,k,0)] = m.addVar(vtype=GRB.BINARY, name=\"h\"+str((n,k,0)))\n",
    "            \n",
    "    # Set objective\n",
    "\n",
    "    m.setObjective( \n",
    "        sum( sum( sum( \n",
    "        h[(n,k_prime,0)]*(-(-w_ub)*λ[(2,n,k_prime,k,1)]             # m is -w_ub\n",
    "                           + w_lb*λ[(3,n,k_prime,k,1)]              # m is w_lb\n",
    "                           - w_ub*λ[(4,n,k_prime,k,1)])             # M is w_ub\n",
    "            for k in range(K)) for k_prime in range(K)) for n in range(N))\n",
    "        + reg_factor1*sum( sum ( abs_alpha[(d,k,0)]  for k in range(K)) for d in range(D)),\n",
    "                   GRB.MINIMIZE)\n",
    "        \n",
    "   # Add constraints \n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            m.addConstr(sum(alpha[(d,k,0)]*x[n,d] for d in range(D)) + beta[(k,0)] \n",
    "                        <= -epsilon + (D*w_ub+b_ub + epsilon)*h[(n,k,0)], name=\"C1 Binary Neuron \"+str((n,k,0)))\n",
    "            \n",
    "            m.addConstr(sum(alpha[(d,k,0)]*x[n,d] for d in range(D)) + beta[(k,0)] \n",
    "                        >= epsilon + (D*w_lb+b_lb - epsilon)*(1-h[(n,k,0)]), name=\"C2 Binary Neuron \"+str((n,k,0)))\n",
    "    \n",
    "    for k in range(K):\n",
    "        for d in range(D):\n",
    "            m.addConstr(alpha[(d,k,0)] <= abs_alpha[(d,k,0)])\n",
    "            m.addConstr(-alpha[(d,k,0)] <= abs_alpha[(d,k,0)])\n",
    "            \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "        if \"abs_alpha\" in v.varName:\n",
    "            continue\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3f11121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_l(layer, λ):\n",
    "    \n",
    "    # Create a new model\n",
    "    m = gp.Model(\"l-th layer\")\n",
    "    \n",
    "    l = layer # layer to be solved for\n",
    "    \n",
    "    # Create variables\n",
    "\n",
    "    z = {}\n",
    "    alpha = {}\n",
    "    abs_alpha = {}\n",
    "    beta = {}\n",
    "    h = {}\n",
    "    \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            for k_prime in range(K):\n",
    "                z[(n,k_prime,k,l)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name= \"z\"+str((n,k_prime,k,l)))\n",
    "                \n",
    "            h[(n,k,l)] = m.addVar(vtype=GRB.BINARY, name=\"h\"+str((n,k,l)))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            alpha[(k_prime,k,l)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,k,l)))\n",
    "            abs_alpha[(k_prime,k,l)] = m.addVar(lb=0, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"abs_alpha\"+str((k_prime,k,l)))\n",
    "        \n",
    "        beta[(k,l)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((k,l)))\n",
    "        \n",
    "    # Set objective\n",
    "        \n",
    "    m.setObjective( \n",
    "        sum( sum( sum( \n",
    "            z[(n,k_prime,k,l)]*(- λ[(2,n,k_prime,k,l)] \n",
    "                                - λ[(3,n,k_prime,k,l)] \n",
    "                                + λ[(4,n,k_prime,k,l)])\n",
    "            + h[(n,k_prime,l)]*(-(-w_ub)*λ[(2,n,k_prime,k,l+1)]            # m is w_lb-w_ub\n",
    "                                + w_lb*λ[(3,n,k_prime,k,l+1)]              # m is w_lb\n",
    "                                - w_ub*λ[(4,n,k_prime,k,l+1)])             # M is w_ub\n",
    "            + alpha[(k_prime,k,l)]*(λ[(2,n,k_prime,k,l)])\n",
    "            for k in range(K)) for k_prime in range(K)) for n in range(N))\n",
    "        + reg_factor2*sum( sum ( abs_alpha[(k_prime,k,l)] for k in range(K)) for k_prime in range(K))\n",
    "        , GRB.MINIMIZE)\n",
    "    \n",
    "    # Add constraints\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            m.addConstr(sum(z[(n,k_prime,k,l)] for k_prime in range(K)) + beta[(k,l)] \n",
    "                        <= -epsilon + (K*w_ub+b_ub + epsilon)*h[(n,k,l)], name=\"C1 Binary Neuron \"+str((n,k,l))) \n",
    "\n",
    "            m.addConstr(sum(z[(n,k_prime,k,l)] for k_prime in range(K)) + beta[(k,l)] \n",
    "                        >= epsilon + (K*w_lb+b_lb - epsilon)*(1-h[(n,k,l)]), name=\"C2 Binary Neuron \"+str((n,k,l)))\n",
    "            \n",
    "            for k_prime in range(K):\n",
    "                m.addConstr(z[(n,k_prime,k,l)] <= alpha[(k_prime,k,l)], name=\"Explicit z-alpha Bound \"+str((n,k_prime,k,l)))\n",
    "    \n",
    "    for k in range(K):\n",
    "        for k_prime in range(K):\n",
    "            m.addConstr(alpha[(k_prime,k,l)] <= abs_alpha[(k_prime,k,l)])\n",
    "            m.addConstr(-alpha[(k_prime,k,l)] <= abs_alpha[(k_prime,k,l)])\n",
    "    \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "        if \"abs_alpha\" in v.varName:\n",
    "            continue\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48d2d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_penultimate_L(λ):\n",
    "    \n",
    "    # Create a new model\n",
    "    m = gp.Model(\"L-1st layer\")\n",
    "        \n",
    "    # Create variables\n",
    "    \n",
    "    z = {}\n",
    "    alpha = {}\n",
    "    abs_alpha = {}\n",
    "    beta = {}\n",
    "    h = {}\n",
    "    \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            for k_prime in range(K):\n",
    "                z[(n,k_prime,k,L-1)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name= \"z\"+str((n,k_prime,k,L-1)))\n",
    "                \n",
    "            h[(n,k,L-1)] = m.addVar(vtype=GRB.BINARY, name=\"h\"+str((n,k,L-1)))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            alpha[(k_prime,k,L-1)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,k,L-1)))\n",
    "            abs_alpha[(k_prime,k,L-1)] = m.addVar(lb=0, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"abs_alpha\"+str((k_prime,k,L-1)))\n",
    "            \n",
    "        beta[(k,L-1)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((k,L-1)))\n",
    "        \n",
    "    # Set objective\n",
    "    \n",
    "    m.setObjective( \n",
    "        sum( sum( sum( \n",
    "            z[(n,k_prime,k,L-1)]*(- λ[(2,n,k_prime,k,L-1)]\n",
    "                                  - λ[(3,n,k_prime,k,L-1)]\n",
    "                                  + λ[(4,n,k_prime,k,L-1)]) \n",
    "            + alpha[(k_prime,k,L-1)]*(λ[(2,n,k_prime,k,L-1)]) for k in range(K))\n",
    "                 + h[(n,k_prime,L-1)]*(-(-w_ub)*λ[(2,n,k_prime,0,L)]              # m is -w_ub\n",
    "                                       + w_lb*λ[(3,n,k_prime,0,L)]                # m is w_lb\n",
    "                                       - w_ub*λ[(4,n,k_prime,0,L)])               # M is w_ub\n",
    "                 for k_prime in range(K)) for n in range(N))\n",
    "        + reg_factor2*sum( sum( abs_alpha[(k_prime,k,L-1)] for k in range(K)) for k_prime in range(K))\n",
    "        , GRB.MINIMIZE)\n",
    "    \n",
    "    # Add constraints\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            m.addConstr(sum(z[(n,k_prime,k,L-1)] for k_prime in range(K)) + beta[(k,L-1)] \n",
    "                        <= -epsilon + (K*w_ub+b_ub + epsilon)*h[(n,k,L-1)], name=\"C1 Binary Neuron \"+str((n,k,L-1))) \n",
    "\n",
    "            m.addConstr(sum(z[(n,k_prime,k,L-1)] for k_prime in range(K)) + beta[(k,L-1)] \n",
    "                        >= epsilon + (K*w_lb+b_lb - epsilon)*(1-h[(n,k,L-1)]), name=\"C2 Binary Neuron \"+str((n,k,L-1)))\n",
    "        \n",
    "            for k_prime in range(K):\n",
    "                m.addConstr(z[(n,k_prime,k,L-1)] <= alpha[(k_prime,k,L-1)], name=\"Explicit z-alpha Bound \"+str((n,k_prime,k,L-1)))\n",
    "\n",
    "    for k in range(K):\n",
    "        for k_prime in range(K):\n",
    "            m.addConstr(alpha[(k_prime,k,L-1)] <= abs_alpha[(k_prime,k,L-1)])\n",
    "            m.addConstr(-alpha[(k_prime,k,L-1)] <= abs_alpha[(k_prime,k,L-1)])\n",
    "    \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "        if \"abs_alpha\" in v.varName:\n",
    "            continue\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d629a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_L(λ):\n",
    "    \n",
    "    # Create a new model\n",
    "    m = gp.Model(\"L-th layer\")\n",
    "        \n",
    "    # Create variables\n",
    "    \n",
    "    z = {}\n",
    "    alpha = {}\n",
    "    abs_alpha = {}\n",
    "    beta = {}\n",
    "    y_hat = {}\n",
    "    loss = {}\n",
    "    \n",
    "    for n in range(N):\n",
    "        \n",
    "        y_hat[n] = m.addVar(vtype=GRB.BINARY, name=\"y_hat\"+str(n))\n",
    "        loss[n] = m.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=\"loss\"+str(n))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            z[(n,k_prime,0,L)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name= \"z\"+str((n,k_prime,0,L)))\n",
    "            \n",
    "    beta[(0,L)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((0,L)))\n",
    "    \n",
    "    for k_prime in range(K):\n",
    "        alpha[(k_prime,0,L)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,0,L)))\n",
    "        abs_alpha[(k_prime,0,L)] = m.addVar(lb=0, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"abs_alpha\"+str((k_prime,0,L)))        \n",
    "            \n",
    "    # Set objective\n",
    "    \n",
    "    m.setObjective(\n",
    "        sum(loss[n] + \n",
    "            sum(z[(n,k_prime,0,L)]*(- λ[(2,n,k_prime,0,L)]\n",
    "                                    - λ[(3,n,k_prime,0,L)]\n",
    "                                    + λ[(4,n,k_prime,0,L)]) \n",
    "                + alpha[(k_prime,0,L)]*(λ[(2,n,k_prime,0,L)]) for k_prime in range(K))\n",
    "            for n in range(N))\n",
    "        + reg_factor3*sum(abs_alpha[(k_prime,0,L)] for k_prime in range(K)), \n",
    "        GRB.MINIMIZE)\n",
    "    \n",
    "    # Add constraints\n",
    "    \n",
    "    for n in range(N):\n",
    "        m.addConstr(sum(z[(n,k_prime,0,L)] for k_prime in range(K)) + beta[(0,L)] \n",
    "                    <= -epsilon + ((K*w_ub)+b_ub + epsilon)*y_hat[n], name=\"C1 Binary Neuron \"+str((n,0,L))) \n",
    "\n",
    "        m.addConstr(sum(z[(n,k_prime,0,L)] for k_prime in range(K)) + beta[(0,L)] \n",
    "                    >= epsilon + ((K*w_lb)+b_lb - epsilon)*(1-y_hat[n]), name=\"C2 Binary Neuron \"+str((n,0,L)))\n",
    "        \n",
    "        m.addConstr(loss[n] >= y[n] - y_hat[n], name = \"C1 Loss Function\"+str(n))\n",
    "        m.addConstr(loss[n] >= -y[n] + y_hat[n], name = \"C2 Loss Function\"+str(n))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            m.addConstr(z[(n,k_prime,0,L)] <= alpha[(k_prime,0,L)], name=\"Explicit z-alpha Bound \"+str((n,k_prime,0,L)))\n",
    "                        \n",
    "    for k_prime in range(K):\n",
    "        m.addConstr(alpha[(k_prime,0,L)] <= abs_alpha[(k_prime,0,L)])\n",
    "        m.addConstr(-alpha[(k_prime,0,L)] <= abs_alpha[(k_prime,0,L)])\n",
    "    \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "        if \"abs_alpha\" in v.varName:\n",
    "            continue\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60106729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def zeta_alpha_l(λ):\n",
    "    \n",
    "#     # Create a new model\n",
    "#     m = gp.Model(\"alpha l-th layer\")\n",
    "        \n",
    "#     # Create variables\n",
    "    \n",
    "#     alpha = {}\n",
    "    \n",
    "#     for k_prime in range(K):\n",
    "#         for k in range(K):\n",
    "#             for l in range(1,L):\n",
    "#                 alpha[(k_prime,k,l)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,k,l)))\n",
    "        \n",
    "#     # Set objective\n",
    "    \n",
    "#     m.setObjective( sum( sum( sum( sum (\n",
    "#         alpha[(k_prime,k,l)]*(-λ[(1,n,k_prime,k,l)]\n",
    "#                              + λ[(2,n,k_prime,k,l)])\n",
    "#                     for l in range(1,L)) for k in range(K)) for k_prime in range(K)) for n in range(N)), \n",
    "#                    GRB.MINIMIZE)\n",
    "    \n",
    "#     # Optimize\n",
    "    \n",
    "#     m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "#     m.optimize()\n",
    "#     m.printQuality()\n",
    "            \n",
    "#     for v in m.getVars():\n",
    "# #         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "#         output[v.varName] = v.x \n",
    "\n",
    "# #     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "#     return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55ae5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def zeta_alpha_L(λ):\n",
    "    \n",
    "#     # Create a new model\n",
    "#     m = gp.Model(\"alpha l-th layer\")\n",
    "        \n",
    "#     # Create variables\n",
    "    \n",
    "#     alpha = {}\n",
    "    \n",
    "#     for k_prime in range(K):\n",
    "#         alpha[(k_prime,0,L)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,0,L)))\n",
    "        \n",
    "#     # Set objective\n",
    "    \n",
    "#     m.setObjective( sum( sum(\n",
    "#         alpha[(k_prime,0,L)]*(-λ[(1,n,k_prime,0,L)]\n",
    "#                              + λ[(2,n,k_prime,0,L)])\n",
    "#                     for k_prime in range(K)) for n in range(N)), \n",
    "#                    GRB.MINIMIZE)\n",
    "    \n",
    "#     # Optimize\n",
    "    \n",
    "#     m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "#     m.optimize()\n",
    "#     m.printQuality()\n",
    "            \n",
    "#     for v in m.getVars():\n",
    "# #         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "#         output[v.varName] = v.x \n",
    "\n",
    "# #     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "#     return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e392bd",
   "metadata": {},
   "source": [
    "### Solving the dual with the Subgradient algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b96c1b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed with the subgradient algorithm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    ## initialize langrange multiplier\n",
    "\n",
    "λ = {} \n",
    "        \n",
    "for n in range(N):\n",
    "    for k_prime in range(K):\n",
    "        for k in range(K):\n",
    "            for l in range(1,L):\n",
    "#                 λ[(1,n,k_prime,k,l)] = 5\n",
    "                λ[(2,n,k_prime,k,l)] = 1\n",
    "                λ[(3,n,k_prime,k,l)] = 3\n",
    "                λ[(4,n,k_prime,k,l)] = 6\n",
    "#         λ[(1,n,k_prime,0,L)] = 7\n",
    "        λ[(2,n,k_prime,0,L)] = 2\n",
    "        λ[(3,n,k_prime,0,L)] = 1\n",
    "        λ[(4,n,k_prime,0,L)] = 0\n",
    "\n",
    "λ_array = list(λ.values())        \n",
    "\n",
    "output = {} # dictionary of outputs\n",
    "\n",
    "    ## Solve subproblems and find the dual objective\n",
    "\n",
    "dual_obj = (zeta_0(λ) + sum(zeta_l(l,λ) for l in range(1,L-1)) + zeta_penultimate_L(λ) + zeta_L(λ)  \n",
    "            + sum( sum( sum( sum(\n",
    "                (-w_ub)*λ[(2,n,k_prime,k,l)] for l in range(1,L)) for k in range(K))\n",
    "                       + (-w_ub)*λ[(2,n,k_prime,0,L)] for k_prime in range(K)) for n in range(N)))\n",
    "\n",
    "    # removed lambda 1 from dual_obj\n",
    "\n",
    "    ## Find the subgradient vector at λ\n",
    "\n",
    "s = {}\n",
    "\n",
    "for n in range(N):\n",
    "    for k_prime in range(K):\n",
    "        for k in range(K):\n",
    "            for l in range(1,L):\n",
    "#                 s[(1,n,k_prime,k,l)] = ( output['z'+str((n,k_prime,k,l))] - output['alpha'+str((k_prime,k,l))] \n",
    "#                                         - (w_ub-w_lb)*(1-output['h'+str((n,k_prime,l-1))]) )\n",
    "\n",
    "                s[(2,n,k_prime,k,l)] = ( -output['z'+str((n,k_prime,k,l))] + output['alpha'+str((k_prime,k,l))] \n",
    "                                        + (w_lb-w_ub)*(1-output['h'+str((n,k_prime,l-1))]) )\n",
    "\n",
    "                s[(3,n,k_prime,k,l)] = ( (w_lb)*output['h'+str((n,k_prime,l-1))] \n",
    "                                        - output['z'+str((n,k_prime,k,l))] )\n",
    "\n",
    "                s[(4,n,k_prime,k,l)] = ( output['z'+str((n,k_prime,k,l))] \n",
    "                                        - (w_ub)*output['h'+str((n,k_prime,l-1))] )\n",
    "\n",
    "#         s[(1,n,k_prime,0,L)] = ( output['z'+str((n,k_prime,0,L))] - output['alpha'+str((k_prime,0,L))] \n",
    "#                                 - (w_ub-w_lb)*(1-output['h'+str((n,k_prime,L-1))]) )\n",
    "\n",
    "        s[(2,n,k_prime,0,L)] = ( -output['z'+str((n,k_prime,0,L))] + output['alpha'+str((k_prime,0,L))] \n",
    "                                + (-w_ub)*(1-output['h'+str((n,k_prime,L-1))]) )\n",
    "\n",
    "        s[(3,n,k_prime,0,L)] = ( (w_lb)*output['h'+str((n,k_prime,L-1))] - output['z'+str((n,k_prime,0,L))] )\n",
    "\n",
    "        s[(4,n,k_prime,0,L)] = ( output['z'+str((n,k_prime,0,L))] - (w_ub)*output['h'+str((n,k_prime,L-1))] )\n",
    "\n",
    "s_array = np.array(list(s.values()))\n",
    "\n",
    "    ## Simple Stepsize\n",
    "\n",
    "# gamma = 1\n",
    "\n",
    "    ## Adaptive Stepsize\n",
    "\n",
    "mu_naught = 2\n",
    "mu = mu_naught\n",
    "\n",
    "Z_best = 0 # Lower bound on primal\n",
    "\n",
    "gamma = mu*((Z_best - dual_obj)/(np.linalg.norm(s_array))**2)\n",
    "\n",
    "    ## Track the projected subgradinet\n",
    "\n",
    "indicator = []\n",
    "\n",
    "for i in range(len(λ_array)):\n",
    "    if (λ_array[i] + gamma*s_array[i]) > 0:\n",
    "        indicator.append(1)\n",
    "    else:\n",
    "        indicator.append(0)\n",
    "\n",
    "indicator = np.array(indicator)\n",
    "projected_s = indicator.T*s_array\n",
    "\n",
    "if (dual_obj >= -1e-6) and (dual_obj_tracker[t]-dual_obj_tracker[t-1] < 1e-6):\n",
    "    print(\"The dual objective roughly optimal\")\n",
    "else:\n",
    "    print(\"Proceed with the subgradient algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecec9954",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subgradient_tracker = [np.linalg.norm(s_array)]\n",
    "dual_obj_tracker = [dual_obj]\n",
    "gamma_tracker = [gamma]\n",
    "projected_s_tracker = [np.linalg.norm(projected_s)]\n",
    "mu_tracker = [mu]\n",
    "\n",
    "adapt_param_factor = 2/3 # try 1/4 and 2/3\n",
    "\n",
    "T = 0 # Number of times Z_{D} did not increase\n",
    "\n",
    "for t in range(1,1000): \n",
    "\n",
    "    if t%100 == 0:\n",
    "        print(\"Iteration count:\", t)\n",
    "    \n",
    "        ## Update λ\n",
    "    \n",
    "    for n in range(N):\n",
    "            for k_prime in range(K):\n",
    "                for k in range(K):\n",
    "                    for l in range(1,L):\n",
    "#                         λ[(1,n,k_prime,k,l)] = max(0, λ[(1,n,k_prime,k,l)] + gamma*s[(1,n,k_prime,k,l)])\n",
    "                        λ[(2,n,k_prime,k,l)] = max(0, λ[(2,n,k_prime,k,l)] + gamma*s[(2,n,k_prime,k,l)])\n",
    "                        λ[(3,n,k_prime,k,l)] = max(0, λ[(3,n,k_prime,k,l)] + gamma*s[(3,n,k_prime,k,l)])\n",
    "                        λ[(4,n,k_prime,k,l)] = max(0, λ[(4,n,k_prime,k,l)] + gamma*s[(4,n,k_prime,k,l)])\n",
    "#                 λ[(1,n,k_prime,0,L)] = max(0, λ[(1,n,k_prime,0,L)] + gamma*s[(1,n,k_prime,0,L)])\n",
    "                λ[(2,n,k_prime,0,L)] = max(0, λ[(2,n,k_prime,0,L)] + gamma*s[(2,n,k_prime,0,L)])\n",
    "                λ[(3,n,k_prime,0,L)] = max(0, λ[(3,n,k_prime,0,L)] + gamma*s[(3,n,k_prime,0,L)])\n",
    "                λ[(4,n,k_prime,0,L)] = max(0, λ[(4,n,k_prime,0,L)] + gamma*s[(4,n,k_prime,0,L)])\n",
    "                \n",
    "    λ_array = np.array(list(λ.values()))\n",
    "\n",
    "        ## Solve subproblems and find the dual objective\n",
    "\n",
    "    dual_obj = (zeta_0(λ) + sum(zeta_l(l,λ) for l in range(1,L-1)) + zeta_penultimate_L(λ) + zeta_L(λ) \n",
    "                + sum( sum( sum( sum(\n",
    "                    (-w_ub)*λ[(2,n,k_prime,k,l)] for l in range(1,L)) for k in range(K)) \n",
    "                           + (-w_ub)*λ[(2,n,k_prime,0,L)] for k_prime in range(K)) for n in range(N)))\n",
    "\n",
    "    # removed lambda 1 from dual_obj\n",
    "    \n",
    "    dual_obj_tracker.append(dual_obj)\n",
    "\n",
    "        ## Find the subgradient vector at λ\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k_prime in range(K):\n",
    "            for k in range(K):\n",
    "                for l in range(1,L):\n",
    "#                     s[(1,n,k_prime,k,l)] = ( output['z'+str((n,k_prime,k,l))] - output['alpha'+str((k_prime,k,l))] \n",
    "#                                             - (w_ub-w_lb)*(1-output['h'+str((n,k_prime,l-1))]) )\n",
    "\n",
    "                    s[(2,n,k_prime,k,l)] = ( -output['z'+str((n,k_prime,k,l))] + output['alpha'+str((k_prime,k,l))] \n",
    "                                            + (-w_ub)*(1-output['h'+str((n,k_prime,l-1))]) )\n",
    "\n",
    "                    s[(3,n,k_prime,k,l)] = ( (w_lb)*output['h'+str((n,k_prime,l-1))] \n",
    "                                            - output['z'+str((n,k_prime,k,l))] )\n",
    "\n",
    "                    s[(4,n,k_prime,k,l)] = ( output['z'+str((n,k_prime,k,l))] \n",
    "                                            - (w_ub)*output['h'+str((n,k_prime,l-1))] )\n",
    "\n",
    "#             s[(1,n,k_prime,0,L)] = ( output['z'+str((n,k_prime,0,L))] - output['alpha'+str((k_prime,0,L))] \n",
    "#                                     - (w_ub-w_lb)*(1-output['h'+str((n,k_prime,L-1))]) )\n",
    "\n",
    "            s[(2,n,k_prime,0,L)] = ( -output['z'+str((n,k_prime,0,L))] + output['alpha'+str((k_prime,0,L))] \n",
    "                                    + (-w_ub)*(1-output['h'+str((n,k_prime,L-1))]) )\n",
    "\n",
    "            s[(3,n,k_prime,0,L)] = ( (w_lb)*output['h'+str((n,k_prime,L-1))] - output['z'+str((n,k_prime,0,L))] )\n",
    "\n",
    "            s[(4,n,k_prime,0,L)] = ( output['z'+str((n,k_prime,0,L))] - (w_ub)*output['h'+str((n,k_prime,L-1))] )\n",
    "\n",
    "    s_array = np.array(list(s.values()))\n",
    "    subgradient_tracker.append(np.linalg.norm(s_array))\n",
    "    \n",
    "        ## Simple step-size\n",
    "    \n",
    "#     gamma = 1/np.sqrt(t) \n",
    "    \n",
    "        ## Adaptive Polyak Stepsize\n",
    "\n",
    "    if dual_obj > Z_best:\n",
    "        Z_best = dual_obj\n",
    "        \n",
    "    if dual_obj < dual_obj_tracker[-2]:\n",
    "        T += 1\n",
    "    else:\n",
    "        T = 0\n",
    "    \n",
    "    if T >= 2: # scaling mu if Z_{D} did not increase in the last 2 iterations\n",
    "        mu = adapt_param_factor*mu\n",
    "        \n",
    "    mu_tracker.append(mu)\n",
    "        \n",
    "    gamma = mu*((Z_best - dual_obj)/(np.linalg.norm(s_array))**2)\n",
    "    gamma_tracker.append(gamma)\n",
    "\n",
    "        ## Track norm of projected subgradinet\n",
    "    \n",
    "    indicator = []\n",
    "\n",
    "    for i in range(len(λ_array)):\n",
    "        if (λ_array[i] + gamma*s_array[i]) < 0:\n",
    "            indicator.append(0)\n",
    "#             indicator[i] = 0\n",
    "        else:\n",
    "            indicator.append(1)\n",
    "            \n",
    "    indicator = np.array(indicator)\n",
    "    projected_s = indicator.T*s_array\n",
    "\n",
    "    projected_s_tracker.append(np.linalg.norm(projected_s))\n",
    "        \n",
    "    if (dual_obj >= -1e-5) and (dual_obj_tracker[t]-dual_obj_tracker[t-1] < 1e-6):\n",
    "        break\n",
    "        \n",
    "        # The lower bound on the primal might not always be 0, but should be??\n",
    "    \n",
    "assert all((x <= 1e-4 and x >= -1e-4) for x in λ_array*s_array), \"Complementary Slackness Conditions are not upheld\"\n",
    "\n",
    "# The product of dual variables and constraints is not exactly 0, but is approximately 0 \n",
    "# (does not hold for [-1e-7,1e-7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3adbad2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "fig.set_size_inches(12, 12)\n",
    "\n",
    "subgrad_y1 = [np.mean(subgradient_tracker[i:i+10]) for i in range(0,len(subgradient_tracker),10)]\n",
    "subgrad_y2 = [np.mean(projected_s_tracker[i:i+10]) for i in range(0,len(projected_s_tracker),10)]\n",
    "\n",
    "ax1.plot([x for x in range(t+1)], dual_obj_tracker, c=\"dodgerblue\")\n",
    "ax2.plot([x for x in range(len(subgrad_y1))], subgrad_y1, c=\"indianred\")\n",
    "ax2.plot([x for x in range(len(subgrad_y2))], subgrad_y2, c=\"dodgerblue\")\n",
    "\n",
    "ax1.set_title(\"Dual Objective (μ0 = {}, α = {})\".format(np.round(mu_naught,2), np.round(adapt_param_factor,2)), fontsize=14)\n",
    "ax2.set_title(\"10-Norm-of-Subgradient Averages (μ0 = {}, α = {})\".format(np.round(mu_naught,2), np.round(adapt_param_factor,2)), fontsize=14)\n",
    "\n",
    "ax2.legend([\"Subgradient\", \"Projected Subgradient\"])\n",
    "\n",
    "ax1.set_xlabel('Iteration Count', fontsize=14)\n",
    "ax2.set_xlabel('Time Averaged-Counts', fontsize=14)\n",
    "\n",
    "filename = 'mu0={} alpha={}.png'.format(np.round(mu_naught,2), np.round(adapt_param_factor,2))\n",
    "plt.savefig(\"Subgradient Plots/\"+filename)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5dba433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"output.json\", \"w\") as outfile: \n",
    "#     json.dump(output, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e4677a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.632856715533596e-06"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e196c911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.   ,  0.   ,  0.   ,  0.   , -0.   , -0.   , -0.   ,  0.   ,\n",
       "        0.   ,  0.   , -0.   , -0.   ,  0.01 , -0.99 , -0.   , -0.   ,\n",
       "        0.   ,  0.   ,  0.   , -0.   , -0.   , -0.   ,  0.   ,  0.   ,\n",
       "        0.   , -0.   , -0.   ,  0.01 , -0.99 , -0.   , -0.   ,  0.   ,\n",
       "        0.   ,  0.   , -0.   , -0.   , -0.   ,  0.   ,  0.   ,  0.   ,\n",
       "       -0.   , -0.   ,  0.   , -0.   , -0.   , -0.   ,  0.   ,  0.   ,\n",
       "        0.   , -0.   , -0.   , -0.   ,  0.   ,  0.   ,  0.   , -0.   ,\n",
       "       -0.   ,  0.   , -0.   , -0.   , -0.   ,  0.   ,  0.   ,  0.   ,\n",
       "       -0.   , -0.   , -0.   ,  0.   ,  0.   ,  0.505, -0.   , -0.   ,\n",
       "        0.   , -0.   , -0.   , -0.   ,  0.   ,  0.   ,  0.   , -0.   ,\n",
       "       -0.   , -0.   ,  0.   ,  0.   ,  0.505, -0.   , -0.   , -0.   ,\n",
       "       -0.   ,  0.   , -0.   ,  0.   ,  0.   ,  0.   , -0.   , -0.   ,\n",
       "       -0.   ,  0.   ,  0.   ,  0.   , -0.   , -0.   ,  0.01 , -0.99 ,\n",
       "       -0.   , -0.   ,  0.   ,  0.   ,  0.   , -0.   , -0.   , -0.   ,\n",
       "        0.   ,  0.   ,  0.   , -0.   , -0.   ,  0.01 , -0.99 , -0.   ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adcbe355",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.   ,  0.   ,  0.   ,  0.   , -1.   , -1.   , -1.   ,  0.   ,\n",
       "        0.   ,  0.   , -1.   , -1.   ,  0.01 , -0.99 , -1.01 , -1.   ,\n",
       "        0.   ,  0.   ,  0.   , -1.   , -1.   , -1.   ,  0.   ,  0.   ,\n",
       "        0.   , -1.   , -1.   ,  0.01 , -0.99 , -1.01 , -1.   ,  0.   ,\n",
       "        0.   ,  0.   , -1.   , -1.   , -1.   ,  0.   ,  0.   ,  0.   ,\n",
       "       -1.   , -1.   ,  0.   , -1.   , -1.   , -1.   ,  0.   ,  0.   ,\n",
       "        0.   , -1.   , -1.   , -1.   ,  0.   ,  0.   ,  0.   , -1.   ,\n",
       "       -1.   ,  0.   , -1.   , -1.   , -1.   ,  0.   ,  0.   ,  0.   ,\n",
       "       -1.   , -1.   , -1.   ,  0.   ,  0.   ,  0.505, -0.495, -1.505,\n",
       "        0.   , -1.   , -1.   , -1.   ,  0.   ,  0.   ,  0.   , -1.   ,\n",
       "       -1.   , -1.   ,  0.   ,  0.   ,  0.505, -0.495, -1.505, -1.   ,\n",
       "       -0.   ,  0.   , -1.   ,  0.   ,  0.   ,  0.   , -1.   , -1.   ,\n",
       "       -1.   ,  0.   ,  0.   ,  0.   , -1.   , -1.   ,  0.01 , -0.99 ,\n",
       "       -1.01 , -1.   ,  0.   ,  0.   ,  0.   , -1.   , -1.   , -1.   ,\n",
       "        0.   ,  0.   ,  0.   , -1.   , -1.   ,  0.01 , -0.99 , -1.01 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3100def3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.98177910e-08,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -9.98177910e-08, -0.00000000e+00, -9.98177910e-08,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.97658992e-07, -0.00000000e+00,\n",
       "        1.41136143e-08, -1.47656814e-06, -0.00000000e+00, -9.98177910e-08,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -9.98177910e-08,\n",
       "       -0.00000000e+00, -9.98177910e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.97658992e-07, -0.00000000e+00,  1.41136143e-08,\n",
       "       -1.47656814e-06, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -9.98177910e-08, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.97658992e-07, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -9.98177910e-08, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.97658992e-07,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -9.98177910e-08, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -9.98177910e-08,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -9.98177910e-08,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -9.98177910e-08, -0.00000000e+00,\n",
       "       -9.98177910e-08,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.97658992e-07, -0.00000000e+00,  1.41136143e-08, -1.47656814e-06,\n",
       "       -0.00000000e+00, -9.98177910e-08,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -9.98177910e-08, -0.00000000e+00, -9.98177910e-08,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.97658992e-07,\n",
       "       -0.00000000e+00,  1.41136143e-08, -1.47656814e-06, -0.00000000e+00])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ_array*s_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39377112",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 0, 0, 0, 1): 9.981779099928514e-08,\n",
       " (3, 0, 0, 0, 1): 0,\n",
       " (4, 0, 0, 0, 1): 0,\n",
       " (2, 0, 0, 0, 2): 0,\n",
       " (3, 0, 0, 0, 2): 9.981779099928514e-08,\n",
       " (4, 0, 0, 0, 2): 0,\n",
       " (2, 0, 0, 1, 1): 9.981779099928514e-08,\n",
       " (3, 0, 0, 1, 1): 0,\n",
       " (4, 0, 0, 1, 1): 0,\n",
       " (2, 0, 0, 1, 2): 0,\n",
       " (3, 0, 0, 1, 2): 1.9765899207779223e-07,\n",
       " (4, 0, 0, 1, 2): 0,\n",
       " (2, 0, 0, 0, 3): 1.4113614336257762e-06,\n",
       " (3, 0, 0, 0, 3): 1.4914829708139534e-06,\n",
       " (4, 0, 0, 0, 3): 0,\n",
       " (2, 0, 1, 0, 1): 9.981779099928514e-08,\n",
       " (3, 0, 1, 0, 1): 0,\n",
       " (4, 0, 1, 0, 1): 0,\n",
       " (2, 0, 1, 0, 2): 0,\n",
       " (3, 0, 1, 0, 2): 9.981779099928514e-08,\n",
       " (4, 0, 1, 0, 2): 0,\n",
       " (2, 0, 1, 1, 1): 9.981779099928514e-08,\n",
       " (3, 0, 1, 1, 1): 0,\n",
       " (4, 0, 1, 1, 1): 0,\n",
       " (2, 0, 1, 1, 2): 0,\n",
       " (3, 0, 1, 1, 2): 1.9765899207779223e-07,\n",
       " (4, 0, 1, 1, 2): 0,\n",
       " (2, 0, 1, 0, 3): 1.411361433625777e-06,\n",
       " (3, 0, 1, 0, 3): 1.4914829708139805e-06,\n",
       " (4, 0, 1, 0, 3): 0,\n",
       " (2, 1, 0, 0, 1): 0,\n",
       " (3, 1, 0, 0, 1): 0,\n",
       " (4, 1, 0, 0, 1): 0,\n",
       " (2, 1, 0, 0, 2): 0,\n",
       " (3, 1, 0, 0, 2): 9.981779099928514e-08,\n",
       " (4, 1, 0, 0, 2): 0,\n",
       " (2, 1, 0, 1, 1): 0,\n",
       " (3, 1, 0, 1, 1): 0,\n",
       " (4, 1, 0, 1, 1): 0,\n",
       " (2, 1, 0, 1, 2): 0,\n",
       " (3, 1, 0, 1, 2): 1.9765899207779223e-07,\n",
       " (4, 1, 0, 1, 2): 0,\n",
       " (2, 1, 0, 0, 3): 0,\n",
       " (3, 1, 0, 0, 3): 0,\n",
       " (4, 1, 0, 0, 3): 0,\n",
       " (2, 1, 1, 0, 1): 0,\n",
       " (3, 1, 1, 0, 1): 0,\n",
       " (4, 1, 1, 0, 1): 0,\n",
       " (2, 1, 1, 0, 2): 0,\n",
       " (3, 1, 1, 0, 2): 9.981779099928514e-08,\n",
       " (4, 1, 1, 0, 2): 0,\n",
       " (2, 1, 1, 1, 1): 0,\n",
       " (3, 1, 1, 1, 1): 0,\n",
       " (4, 1, 1, 1, 1): 0,\n",
       " (2, 1, 1, 1, 2): 0,\n",
       " (3, 1, 1, 1, 2): 1.9765899207779223e-07,\n",
       " (4, 1, 1, 1, 2): 0,\n",
       " (2, 1, 1, 0, 3): 0,\n",
       " (3, 1, 1, 0, 3): 0,\n",
       " (4, 1, 1, 0, 3): 0,\n",
       " (2, 2, 0, 0, 1): 0,\n",
       " (3, 2, 0, 0, 1): 0,\n",
       " (4, 2, 0, 0, 1): 0,\n",
       " (2, 2, 0, 0, 2): 0,\n",
       " (3, 2, 0, 0, 2): 9.981779099928514e-08,\n",
       " (4, 2, 0, 0, 2): 0,\n",
       " (2, 2, 0, 1, 1): 0,\n",
       " (3, 2, 0, 1, 1): 0,\n",
       " (4, 2, 0, 1, 1): 0,\n",
       " (2, 2, 0, 1, 2): 0,\n",
       " (3, 2, 0, 1, 2): 0,\n",
       " (4, 2, 0, 1, 2): 0,\n",
       " (2, 2, 0, 0, 3): 0,\n",
       " (3, 2, 0, 0, 3): 0,\n",
       " (4, 2, 0, 0, 3): 0,\n",
       " (2, 2, 1, 0, 1): 0,\n",
       " (3, 2, 1, 0, 1): 0,\n",
       " (4, 2, 1, 0, 1): 0,\n",
       " (2, 2, 1, 0, 2): 0,\n",
       " (3, 2, 1, 0, 2): 9.981779099928514e-08,\n",
       " (4, 2, 1, 0, 2): 0,\n",
       " (2, 2, 1, 1, 1): 0,\n",
       " (3, 2, 1, 1, 1): 0,\n",
       " (4, 2, 1, 1, 1): 0,\n",
       " (2, 2, 1, 1, 2): 0,\n",
       " (3, 2, 1, 1, 2): 0,\n",
       " (4, 2, 1, 1, 2): 0,\n",
       " (2, 2, 1, 0, 3): 0,\n",
       " (3, 2, 1, 0, 3): 0,\n",
       " (4, 2, 1, 0, 3): 0,\n",
       " (2, 3, 0, 0, 1): 9.981779099928514e-08,\n",
       " (3, 3, 0, 0, 1): 0,\n",
       " (4, 3, 0, 0, 1): 0,\n",
       " (2, 3, 0, 0, 2): 0,\n",
       " (3, 3, 0, 0, 2): 9.981779099928514e-08,\n",
       " (4, 3, 0, 0, 2): 0,\n",
       " (2, 3, 0, 1, 1): 9.981779099928514e-08,\n",
       " (3, 3, 0, 1, 1): 0,\n",
       " (4, 3, 0, 1, 1): 0,\n",
       " (2, 3, 0, 1, 2): 0,\n",
       " (3, 3, 0, 1, 2): 1.9765899207779223e-07,\n",
       " (4, 3, 0, 1, 2): 0,\n",
       " (2, 3, 0, 0, 3): 1.4113614336257762e-06,\n",
       " (3, 3, 0, 0, 3): 1.4914829708139534e-06,\n",
       " (4, 3, 0, 0, 3): 0,\n",
       " (2, 3, 1, 0, 1): 9.981779099928514e-08,\n",
       " (3, 3, 1, 0, 1): 0,\n",
       " (4, 3, 1, 0, 1): 0,\n",
       " (2, 3, 1, 0, 2): 0,\n",
       " (3, 3, 1, 0, 2): 9.981779099928514e-08,\n",
       " (4, 3, 1, 0, 2): 0,\n",
       " (2, 3, 1, 1, 1): 9.981779099928514e-08,\n",
       " (3, 3, 1, 1, 1): 0,\n",
       " (4, 3, 1, 1, 1): 0,\n",
       " (2, 3, 1, 1, 2): 0,\n",
       " (3, 3, 1, 1, 2): 1.9765899207779223e-07,\n",
       " (4, 3, 1, 1, 2): 0,\n",
       " (2, 3, 1, 0, 3): 1.411361433625777e-06,\n",
       " (3, 3, 1, 0, 3): 1.4914829708139805e-06,\n",
       " (4, 3, 1, 0, 3): 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "342aedb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 0, 0, 0, 1): -1.0,\n",
       " (3, 0, 0, 0, 1): 0.0,\n",
       " (4, 0, 0, 0, 1): 0.0,\n",
       " (2, 0, 0, 0, 2): 0.0,\n",
       " (3, 0, 0, 0, 2): -1.0,\n",
       " (4, 0, 0, 0, 2): -1.0,\n",
       " (2, 0, 0, 1, 1): -1.0,\n",
       " (3, 0, 0, 1, 1): 0.0,\n",
       " (4, 0, 0, 1, 1): 0.0,\n",
       " (2, 0, 0, 1, 2): 0.0,\n",
       " (3, 0, 0, 1, 2): -1.0,\n",
       " (4, 0, 0, 1, 2): -1.0,\n",
       " (2, 0, 0, 0, 3): 0.009999999999999893,\n",
       " (3, 0, 0, 0, 3): -0.9900000000000001,\n",
       " (4, 0, 0, 0, 3): -1.0099999999999998,\n",
       " (2, 0, 1, 0, 1): -1.0,\n",
       " (3, 0, 1, 0, 1): 0.0,\n",
       " (4, 0, 1, 0, 1): 0.0,\n",
       " (2, 0, 1, 0, 2): 0.0,\n",
       " (3, 0, 1, 0, 2): -1.0,\n",
       " (4, 0, 1, 0, 2): -1.0,\n",
       " (2, 0, 1, 1, 1): -1.0,\n",
       " (3, 0, 1, 1, 1): 0.0,\n",
       " (4, 0, 1, 1, 1): 0.0,\n",
       " (2, 0, 1, 1, 2): 0.0,\n",
       " (3, 0, 1, 1, 2): -1.0,\n",
       " (4, 0, 1, 1, 2): -1.0,\n",
       " (2, 0, 1, 0, 3): 0.009999999999999894,\n",
       " (3, 0, 1, 0, 3): -0.9900000000000001,\n",
       " (4, 0, 1, 0, 3): -1.0099999999999998,\n",
       " (2, 1, 0, 0, 1): -1.0,\n",
       " (3, 1, 0, 0, 1): 0.0,\n",
       " (4, 1, 0, 0, 1): 0.0,\n",
       " (2, 1, 0, 0, 2): 0.0,\n",
       " (3, 1, 0, 0, 2): -1.0,\n",
       " (4, 1, 0, 0, 2): -1.0,\n",
       " (2, 1, 0, 1, 1): -1.0,\n",
       " (3, 1, 0, 1, 1): 0.0,\n",
       " (4, 1, 0, 1, 1): 0.0,\n",
       " (2, 1, 0, 1, 2): 0.0,\n",
       " (3, 1, 0, 1, 2): -1.0,\n",
       " (4, 1, 0, 1, 2): -1.0,\n",
       " (2, 1, 0, 0, 3): 0.0,\n",
       " (3, 1, 0, 0, 3): -1.0,\n",
       " (4, 1, 0, 0, 3): -1.0,\n",
       " (2, 1, 1, 0, 1): -1.0,\n",
       " (3, 1, 1, 0, 1): 0.0,\n",
       " (4, 1, 1, 0, 1): 0.0,\n",
       " (2, 1, 1, 0, 2): 0.0,\n",
       " (3, 1, 1, 0, 2): -1.0,\n",
       " (4, 1, 1, 0, 2): -1.0,\n",
       " (2, 1, 1, 1, 1): -1.0,\n",
       " (3, 1, 1, 1, 1): 0.0,\n",
       " (4, 1, 1, 1, 1): 0.0,\n",
       " (2, 1, 1, 1, 2): 0.0,\n",
       " (3, 1, 1, 1, 2): -1.0,\n",
       " (4, 1, 1, 1, 2): -1.0,\n",
       " (2, 1, 1, 0, 3): 0.0,\n",
       " (3, 1, 1, 0, 3): -1.0,\n",
       " (4, 1, 1, 0, 3): -1.0,\n",
       " (2, 2, 0, 0, 1): -1.0,\n",
       " (3, 2, 0, 0, 1): 0.0,\n",
       " (4, 2, 0, 0, 1): 0.0,\n",
       " (2, 2, 0, 0, 2): 0.0,\n",
       " (3, 2, 0, 0, 2): -1.0,\n",
       " (4, 2, 0, 0, 2): -1.0,\n",
       " (2, 2, 0, 1, 1): -1.0,\n",
       " (3, 2, 0, 1, 1): 0.0,\n",
       " (4, 2, 0, 1, 1): 0.0,\n",
       " (2, 2, 0, 1, 2): 0.5050000000000003,\n",
       " (3, 2, 0, 1, 2): -0.49499999999999966,\n",
       " (4, 2, 0, 1, 2): -1.5050000000000003,\n",
       " (2, 2, 0, 0, 3): 0.0,\n",
       " (3, 2, 0, 0, 3): -1.0,\n",
       " (4, 2, 0, 0, 3): -1.0,\n",
       " (2, 2, 1, 0, 1): -1.0,\n",
       " (3, 2, 1, 0, 1): 0.0,\n",
       " (4, 2, 1, 0, 1): 0.0,\n",
       " (2, 2, 1, 0, 2): 0.0,\n",
       " (3, 2, 1, 0, 2): -1.0,\n",
       " (4, 2, 1, 0, 2): -1.0,\n",
       " (2, 2, 1, 1, 1): -1.0,\n",
       " (3, 2, 1, 1, 1): 0.0,\n",
       " (4, 2, 1, 1, 1): 0.0,\n",
       " (2, 2, 1, 1, 2): 0.5050000000000003,\n",
       " (3, 2, 1, 1, 2): -0.49499999999999966,\n",
       " (4, 2, 1, 1, 2): -1.5050000000000003,\n",
       " (2, 2, 1, 0, 3): -1.0,\n",
       " (3, 2, 1, 0, 3): -0.0,\n",
       " (4, 2, 1, 0, 3): 0.0,\n",
       " (2, 3, 0, 0, 1): -1.0,\n",
       " (3, 3, 0, 0, 1): 0.0,\n",
       " (4, 3, 0, 0, 1): 0.0,\n",
       " (2, 3, 0, 0, 2): 0.0,\n",
       " (3, 3, 0, 0, 2): -1.0,\n",
       " (4, 3, 0, 0, 2): -1.0,\n",
       " (2, 3, 0, 1, 1): -1.0,\n",
       " (3, 3, 0, 1, 1): 0.0,\n",
       " (4, 3, 0, 1, 1): 0.0,\n",
       " (2, 3, 0, 1, 2): 0.0,\n",
       " (3, 3, 0, 1, 2): -1.0,\n",
       " (4, 3, 0, 1, 2): -1.0,\n",
       " (2, 3, 0, 0, 3): 0.009999999999999893,\n",
       " (3, 3, 0, 0, 3): -0.9900000000000001,\n",
       " (4, 3, 0, 0, 3): -1.0099999999999998,\n",
       " (2, 3, 1, 0, 1): -1.0,\n",
       " (3, 3, 1, 0, 1): 0.0,\n",
       " (4, 3, 1, 0, 1): 0.0,\n",
       " (2, 3, 1, 0, 2): 0.0,\n",
       " (3, 3, 1, 0, 2): -1.0,\n",
       " (4, 3, 1, 0, 2): -1.0,\n",
       " (2, 3, 1, 1, 1): -1.0,\n",
       " (3, 3, 1, 1, 1): 0.0,\n",
       " (4, 3, 1, 1, 1): 0.0,\n",
       " (2, 3, 1, 1, 2): 0.0,\n",
       " (3, 3, 1, 1, 2): -1.0,\n",
       " (4, 3, 1, 1, 2): -1.0,\n",
       " (2, 3, 1, 0, 3): 0.009999999999999894,\n",
       " (3, 3, 1, 0, 3): -0.9900000000000001,\n",
       " (4, 3, 1, 0, 3): -1.0099999999999998}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb08e6f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta(0, 0)': -1.0,\n",
       " 'alpha(0, 0, 0)': 0.0,\n",
       " 'alpha(1, 0, 0)': 0.0,\n",
       " 'h(0, 0, 0)': -0.0,\n",
       " 'h(1, 0, 0)': -0.0,\n",
       " 'h(2, 0, 0)': -0.0,\n",
       " 'h(3, 0, 0)': -0.0,\n",
       " 'beta(1, 0)': -1.0,\n",
       " 'alpha(0, 1, 0)': 0.0,\n",
       " 'alpha(1, 1, 0)': 0.0,\n",
       " 'h(0, 1, 0)': -0.0,\n",
       " 'h(1, 1, 0)': -0.0,\n",
       " 'h(2, 1, 0)': -0.0,\n",
       " 'h(3, 1, 0)': -0.0,\n",
       " 'z(0, 0, 0, 1)': 0.0,\n",
       " 'z(0, 1, 0, 1)': 0.0,\n",
       " 'h(0, 0, 1)': 1.0,\n",
       " 'z(1, 0, 0, 1)': 0.0,\n",
       " 'z(1, 1, 0, 1)': 0.0,\n",
       " 'h(1, 0, 1)': 1.0,\n",
       " 'z(2, 0, 0, 1)': 0.0,\n",
       " 'z(2, 1, 0, 1)': 0.0,\n",
       " 'h(2, 0, 1)': 1.0,\n",
       " 'z(3, 0, 0, 1)': 0.0,\n",
       " 'z(3, 1, 0, 1)': 0.0,\n",
       " 'h(3, 0, 1)': 1.0,\n",
       " 'alpha(0, 0, 1)': 0.0,\n",
       " 'alpha(1, 0, 1)': 0.0,\n",
       " 'beta(0, 1)': 1.0,\n",
       " 'z(0, 0, 1, 1)': 0.0,\n",
       " 'z(0, 1, 1, 1)': 0.0,\n",
       " 'h(0, 1, 1)': 1.0,\n",
       " 'z(1, 0, 1, 1)': 0.0,\n",
       " 'z(1, 1, 1, 1)': 0.0,\n",
       " 'h(1, 1, 1)': 1.0,\n",
       " 'z(2, 0, 1, 1)': 0.0,\n",
       " 'z(2, 1, 1, 1)': 0.0,\n",
       " 'h(2, 1, 1)': 1.0,\n",
       " 'z(3, 0, 1, 1)': 0.0,\n",
       " 'z(3, 1, 1, 1)': 0.0,\n",
       " 'h(3, 1, 1)': 1.0,\n",
       " 'alpha(0, 1, 1)': 0.0,\n",
       " 'alpha(1, 1, 1)': 0.0,\n",
       " 'beta(1, 1)': 1.0,\n",
       " 'z(0, 0, 0, 2)': 0.0,\n",
       " 'z(0, 1, 0, 2)': 0.0,\n",
       " 'h(0, 0, 2)': 1.0,\n",
       " 'z(1, 0, 0, 2)': 0.0,\n",
       " 'z(1, 1, 0, 2)': 0.0,\n",
       " 'h(1, 0, 2)': 1.0,\n",
       " 'z(2, 0, 0, 2)': 0.0,\n",
       " 'z(2, 1, 0, 2)': 0.0,\n",
       " 'h(2, 0, 2)': 1.0,\n",
       " 'z(3, 0, 0, 2)': 0.0,\n",
       " 'z(3, 1, 0, 2)': 0.0,\n",
       " 'h(3, 0, 2)': 1.0,\n",
       " 'alpha(0, 0, 2)': 0.0,\n",
       " 'alpha(1, 0, 2)': 0.0,\n",
       " 'beta(0, 2)': 0.009999999999999787,\n",
       " 'z(0, 0, 1, 2)': 0.0,\n",
       " 'z(0, 1, 1, 2)': 0.0,\n",
       " 'h(0, 1, 2)': 1.0,\n",
       " 'z(1, 0, 1, 2)': 0.0,\n",
       " 'z(1, 1, 1, 2)': 0.0,\n",
       " 'h(1, 1, 2)': 1.0,\n",
       " 'z(2, 0, 1, 2)': -0.5050000000000003,\n",
       " 'z(2, 1, 1, 2)': -0.5050000000000003,\n",
       " 'h(2, 1, 2)': 0.0,\n",
       " 'z(3, 0, 1, 2)': 0.0,\n",
       " 'z(3, 1, 1, 2)': 0.0,\n",
       " 'h(3, 1, 2)': 1.0,\n",
       " 'alpha(0, 1, 2)': 0.0,\n",
       " 'alpha(1, 1, 2)': 0.0,\n",
       " 'beta(1, 2)': 0.009999999999999787,\n",
       " 'y_hat0': -0.0,\n",
       " 'loss0': 0.0,\n",
       " 'z(0, 0, 0, 3)': -0.009999999999999893,\n",
       " 'z(0, 1, 0, 3)': -0.009999999999999894,\n",
       " 'y_hat1': 1.0,\n",
       " 'loss1': 0.0,\n",
       " 'z(1, 0, 0, 3)': 0.0,\n",
       " 'z(1, 1, 0, 3)': 0.0,\n",
       " 'y_hat2': 1.0,\n",
       " 'loss2': 0.0,\n",
       " 'z(2, 0, 0, 3)': 0.0,\n",
       " 'z(2, 1, 0, 3)': 0.0,\n",
       " 'y_hat3': -0.0,\n",
       " 'loss3': 0.0,\n",
       " 'z(3, 0, 0, 3)': -0.009999999999999893,\n",
       " 'z(3, 1, 0, 3)': -0.009999999999999894,\n",
       " 'beta(0, 3)': 0.009999999999999787,\n",
       " 'alpha(0, 0, 3)': 0.0,\n",
       " 'alpha(1, 0, 3)': 0.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a23d34",
   "metadata": {},
   "source": [
    "### Primal Feasible Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "659d026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XOR 0 = 1.0 Should be  0.0\n",
      "0 XOR 1 = 1.0 Should be  1.0\n",
      "1 XOR 0 = 1.0 Should be  1.0\n",
      "1 XOR 1 = 1.0 Should be  0.0\n",
      "\n",
      "Prediction Accuracy =  50.0 %\n"
     ]
    }
   ],
   "source": [
    "h = {} # tracks output of units\n",
    "\n",
    "correct_pred = 0\n",
    "\n",
    "for n in range(N):\n",
    "    for k in range(K):\n",
    "        h[(k,0)] = sum(output[\"alpha\"+str((d,k,0))]*x[n,d] for d in range(D)) + output[\"beta\"+str((k,0))]\n",
    "#             print(\"h[\",(k,0),\"] = \", h[(k,0)])\n",
    "\n",
    "        if h[(k,0)] <= 0:\n",
    "            h[(k,0)] = 0\n",
    "        else:\n",
    "            h[(k,0)] = 1\n",
    "#             print(\"h[\",(k,0),\"] = \", h[(k,0)])\n",
    "\n",
    "    for l in range(1,L):\n",
    "        for k in range(K):\n",
    "            h[(k,l)] = sum(output[\"alpha\"+str((k_prime,k,l))]*h[(k_prime,l-1)] for k_prime in range(K)) + output[\"beta\"+str((k,l))]\n",
    "#                 print(\"h[\",(k,l),\"] = \", h[(k,l)])\n",
    "\n",
    "            if h[(k,l)] <= 0:\n",
    "                h[(k,l)] = 0\n",
    "            else:\n",
    "                h[(k,l)] = 1\n",
    "#                 print(\"h[\",(k,l),\"] = \", h[(k,l)])\n",
    "\n",
    "    y_hat = sum(output[\"alpha\"+str((k_prime,0,L))]*h[(k,L-1)] for k in range(K)) + output[\"beta\"+str((0,L))]\n",
    "    if y_hat <= 0:\n",
    "        y_hat = 0\n",
    "    else:\n",
    "        y_hat = 1\n",
    "\n",
    "    if y_hat == y[n]:\n",
    "        correct_pred += 1\n",
    "    \n",
    "    print(x[n][0], \"XOR\", x[n][1], \"=\", float(y_hat), \"Should be \", float(y[n]))\n",
    "\n",
    "print(\"\\nPrediction Accuracy = \", correct_pred/(n+1)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8eff4",
   "metadata": {},
   "source": [
    "### Notes and Questions for 06/01/2021\n",
    "\n",
    "* The reformulation is not suited for $ L = 1 $, but seems to run for $ L \\ge 2 $\n",
    "* Verify that the subgradient is defined appropriately\n",
    "* Explicit bounds on z in the sub-problems?\n",
    "* $ -10^{-3} \\le s \\le 10^{-3} $ or just $ s \\le 10^{-3} $ (neither seem to be converging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae424f6",
   "metadata": {},
   "source": [
    "### Notes and Questions for 06/08/2021\n",
    "\n",
    "* Norm of subgradient is oscillating back and forth with every iteration; not reducing significantly with each iteration\n",
    "* Dual objective is also oscillating but generally increasing quicker than the norm of the subgradient\n",
    "* Step size seems to be the issue; Try the Held-Karp Stepsize\n",
    "\n",
    "***\n",
    "\n",
    "* Try projected subgradient: \"calculate $ x = \\lambda^{t} + \\gamma^{t}s^{t} $, figure out which entries of that vector are negative and have an \"indicator\" vector (call this y for now) has the same length as x but whose entries equal 1 if the corresponding entry of x is non-negative and 0 otherwise. Then multiply $ Ax-b $ by y (i.e. $y^{T}(Ax-b)$) and take the norm of the result. This should go to zero. The reason being is due to the constraint.\"\n",
    "\n",
    "***\n",
    "\n",
    "* Dual Objective still decreasing first and then increasing. Having the same values for all λ in the 0th iteration is always giving the same dual objective. On the other hand, having $ \\lambda^0 $ equal to a variety of values avoids this. Don't know why this means that the 1st iteration gives a better dual objective than when all the $ \\lambda^0 $ are equal though.\n",
    "* Projected subgradient still not converging to 0. \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "##### TODO 06/08/2021\n",
    "* Add a check for the complementary slackness conditions and seeing if they are all zero.  \n",
    "* Add a check that if the objective doesn't change by too much after a few rounds (like objectives in consecutive iterations are within 1e-6 or 1e-4 of each other) then terminate the algorithm. \n",
    "* For the plots, add a time average for the sub gradient (like maybe a sliding window average of 10 iterations or something like that) just to smooth them out a bit and show the over all trajectory.\n",
    "* Recreate a primal feasible solution form this and check the prediction accuracy. Take the values of the coefficients of the ANN from this procedure and let's see how an ANN with those values performs.\n",
    "\n",
    "***\n",
    "\n",
    "__Fixes__: \n",
    "* For the stepsize equation, fixed $ (||s|| \\times 2) $ to $ (||s||^{2}) $ \n",
    "* Fixed adaption parameter scaling from every iteration to when $ Z_{D} $ did not increase in the last 2 iterations\n",
    "* Fixed dual_obj sum from range(1,L-1) to range(1,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d389b4a",
   "metadata": {},
   "source": [
    "### Notes and Questions for 06/15/2021\n",
    "\n",
    "* Add the explicit contraint $ z \\leq \\alpha $\n",
    "    * This means that we can remove $ z - \\alpha \\leq M(1-h) $ from the formulation and from the dual.\n",
    "\n",
    "--> Done. The new problem is that when $ \\alpha = 1 $, z can still be anything it wants in the last layer. Also, we're not seeing $ z_l = 0 $ when $ h_{l-1} = 0 $\n",
    "\n",
    "* Include a regularization term in the objective equal to $ \\sum \\mu(|\\alpha|) $ (so minimize the absolute value of the sum of all the alphas times some constant mu that is small-ish like 0.1)\n",
    "    * $ \\mu $ should be outside of the summation?\n",
    "    \n",
    "* In the objectives, should it be $ h_{n,k\\prime,l} $ or $ h_{n,k,l} $? Changing them makes a difference..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441b5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
