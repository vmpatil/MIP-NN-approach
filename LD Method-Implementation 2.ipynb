{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026ed18e",
   "metadata": {},
   "source": [
    "_Last Updated: 06/21/2021_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c94036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB, abs_\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92caabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,0],[0,1], [1,0], [1,1]])\n",
    "y = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d5962",
   "metadata": {},
   "source": [
    "### Langrangian Relaxation Subproblems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb52087",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = y.shape[0]\n",
    "D = x[0].shape[0] # dimension of data\n",
    "K = 2 # Number of units in each hidden layer\n",
    "L = 3 # Number of hidden layers\n",
    "\n",
    "w_ub, w_lb, b_ub, b_lb = [1,-1,1,-1]\n",
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e59d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_0(λ):\n",
    "\n",
    "    # Create a new model\n",
    "    m = gp.Model(\"0-th layer\")\n",
    "    \n",
    "    # Create variables\n",
    "    \n",
    "    alpha = {}\n",
    "    beta = {}\n",
    "    h = {}\n",
    "\n",
    "    for k in range(K):\n",
    "        beta[(k,0)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((k,0)))\n",
    "        for d in range(D):\n",
    "            alpha[(d,k,0)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((d,k,0)))\n",
    "            \n",
    "        for n in range(N):\n",
    "            h[(n,k,0)] = m.addVar(vtype=GRB.BINARY, name=\"h\"+str((n,k,0)))\n",
    "            \n",
    "    # Set objective\n",
    "\n",
    "    m.setObjective( \n",
    "        sum( sum( sum( -λ[(n,k_prime,k,1)]*h[(n,k_prime,0)] \n",
    "                      for k in range(K)) for k_prime in range(K)) for n in range(N)), GRB.MINIMIZE)\n",
    "        \n",
    "   # Add constraints \n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            m.addConstr(sum(alpha[(d,k,0)]*x[n,d] for d in range(D)) + beta[(k,0)] \n",
    "                        <= (D*w_ub+b_ub + epsilon)*h[(n,k,0)], name=\"C1 Binary Neuron \"+str((n,k,0)))\n",
    "            \n",
    "            m.addConstr(sum(alpha[(d,k,0)]*x[n,d] for d in range(D)) + beta[(k,0)] \n",
    "                        >= epsilon + (D*w_lb+b_lb - epsilon)*(1-h[(n,k,0)]), name=\"C2 Binary Neuron \"+str((n,k,0)))\n",
    "            \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70738c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_l(layer, λ):\n",
    "    \n",
    "    # Create a new model\n",
    "    m = gp.Model(\"l-th layer\")\n",
    "    \n",
    "    l = layer # layer to be solved for\n",
    "    \n",
    "    # Create variables\n",
    "\n",
    "    alpha = {}\n",
    "    beta = {}\n",
    "    z = {}\n",
    "    h = {}\n",
    "    g = {}\n",
    "    \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            for k_prime in range(K):\n",
    "                z[(n,k_prime,k,l)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name= \"z\"+str((n,k_prime,k,l)))\n",
    "                g[(n,k_prime,k,l)] = m.addVar(vtype=GRB.BINARY, name=\"g\"+str((n,k_prime,k,l)))\n",
    "                \n",
    "            h[(n,k,l)] = m.addVar(vtype=GRB.BINARY, name=\"h\"+str((n,k,l)))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            alpha[(k_prime,k,l)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,k,l)))\n",
    "        \n",
    "        beta[(k,l)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((k,l)))\n",
    "        \n",
    "    # Set objective\n",
    "        \n",
    "    m.setObjective( sum( sum( sum( λ[(n,k_prime,k,l)]*g[(n,k_prime,k,l)] \n",
    "                                 - λ[(n,k_prime,k,l+1)]*h[(n,k_prime,l)] \n",
    "                                 for k in range(K)) for k_prime in range(K)) for n in range(N)) ,GRB.MINIMIZE)\n",
    "    \n",
    "    # Add constraints\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            m.addConstr(sum(z[(n,k_prime,k,l)] for k_prime in range(K)) + beta[(k,l)] \n",
    "                        <= (K*w_ub+b_ub + epsilon)*h[(n,k,l)], name=\"C1 Binary Neuron \"+str((n,k,l))) \n",
    "\n",
    "            m.addConstr(sum(z[(n,k_prime,k,l)] for k_prime in range(K)) + beta[(k,l)] \n",
    "                        >= epsilon + (K*w_lb+b_lb - epsilon)*(1-h[(n,k,l)]), name=\"C2 Binary Neuron \"+str((n,k,l)))\n",
    "            \n",
    "            for k_prime in range(K):\n",
    "                m.addConstr(z[(n,k_prime,k,l)] <= alpha[(k_prime,k,l)] + (-w_lb)*(1-g[(n,k_prime,k,l)]), \n",
    "                            name=\"z-alpha Upper Bound \"+str((n,k_prime,k,l)))\n",
    "                m.addConstr(z[(n,k_prime,k,l)] >= alpha[(k_prime,k,l)] + (-w_ub)*(1-g[(n,k_prime,k,l)]), \n",
    "                            name=\"z-alpha Lower Bound\"+str((n,k_prime,k,l)))\n",
    "                m.addConstr(z[(n,k_prime,k,l)] <= (w_ub)*g[(n,k_prime,k,l)], name = \"z-g Upper Bound\"+str((n,k_prime,k,l)))\n",
    "                m.addConstr(z[(n,k_prime,k,l)] >= (w_lb)*g[(n,k_prime,k,l)], name = \"z-g Lower Bound\"+str((n,k_prime,k,l)))\n",
    "                \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264af577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_penultimate_L(λ):\n",
    "    \n",
    "    # Create a new model\n",
    "    m = gp.Model(\"(L-1)st layer\")\n",
    "    \n",
    "    # Create variables\n",
    "\n",
    "    alpha = {}\n",
    "    beta = {}\n",
    "    z = {}\n",
    "    h = {}\n",
    "    g = {}\n",
    "    \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            for k_prime in range(K):\n",
    "                z[(n,k_prime,k,L-1)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name= \"z\"+str((n,k_prime,k,L-1)))\n",
    "                g[(n,k_prime,k,L-1)] = m.addVar(vtype=GRB.BINARY, name=\"g\"+str((n,k_prime,k,L-1)))\n",
    "                \n",
    "            h[(n,k,L-1)] = m.addVar(vtype=GRB.BINARY, name=\"h\"+str((n,k,L-1)))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            alpha[(k_prime,k,L-1)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,k,L-1)))\n",
    "        \n",
    "        beta[(k,L-1)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((k,L-1)))\n",
    "        \n",
    "    # Set objective\n",
    "        \n",
    "    m.setObjective( sum( sum( sum( λ[(n,k_prime,k,L-1)]*g[(n,k_prime,k,L-1)] for k in range(K))\n",
    "                             - λ[(n,k_prime,0,L)]*h[(n,k_prime,L-1)] \n",
    "                             for k_prime in range(K)) for n in range(N))\n",
    "                   ,GRB.MINIMIZE)\n",
    "    \n",
    "    # Add constraints\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            m.addConstr(sum(z[(n,k_prime,k,L-1)] for k_prime in range(K)) + beta[(k,L-1)] \n",
    "                        <= (K*w_ub+b_ub + epsilon)*h[(n,k,L-1)], name=\"C1 Binary Neuron \"+str((n,k,L-1))) \n",
    "\n",
    "            m.addConstr(sum(z[(n,k_prime,k,L-1)] for k_prime in range(K)) + beta[(k,L-1)] \n",
    "                        >= epsilon + (K*w_lb+b_lb - epsilon)*(1-h[(n,k,L-1)]), name=\"C2 Binary Neuron \"+str((n,k,L-1)))\n",
    "            \n",
    "            for k_prime in range(K):\n",
    "                m.addConstr(z[(n,k_prime,k,L-1)] <= alpha[(k_prime,k,L-1)] + (-w_lb)*(1-g[(n,k_prime,k,L-1)]),\n",
    "                            name=\"z-alpha Upper Bound \"+str((n,k_prime,k,L-1)))\n",
    "                m.addConstr(z[(n,k_prime,k,L-1)] >= alpha[(k_prime,k,L-1)] + (-w_ub)*(1-g[(n,k_prime,k,L-1)]), \n",
    "                            name=\"z-alpha Lower Bound\"+str((n,k_prime,k,L-1)))\n",
    "                m.addConstr(z[(n,k_prime,k,L-1)] <= (w_ub)*g[(n,k_prime,k,L-1)], name = \"z-g Upper Bound\"+str((n,k_prime,k,L-1)))\n",
    "                m.addConstr(z[(n,k_prime,k,L-1)] >= (w_lb)*g[(n,k_prime,k,L-1)], name = \"z-g Lower Bound\"+str((n,k_prime,k,L-1)))\n",
    "                \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07712817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta_L(λ):\n",
    "    \n",
    "    # Create a new model\n",
    "    m = gp.Model(\"L-th layer\")\n",
    "        \n",
    "    # Create variables\n",
    "    \n",
    "    alpha = {}\n",
    "    beta = {}\n",
    "    z = {}\n",
    "    g = {}\n",
    "    y_hat = {}\n",
    "    loss = {}\n",
    "    \n",
    "    for n in range(N):\n",
    "        \n",
    "        y_hat[n] = m.addVar(vtype=GRB.BINARY, name=\"y_hat\"+str(n))\n",
    "        loss[n] = m.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=\"loss\"+str(n))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            z[(n,k_prime,0,L)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"z\"+str((n,k_prime,0,L)))\n",
    "            g[(n,k_prime,0,L)] = m.addVar(vtype=GRB.BINARY, name=\"g\"+str((n,k_prime,0,L)))\n",
    "            \n",
    "    beta[(0,L)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((0,L)))\n",
    "    \n",
    "    for k_prime in range(K):\n",
    "        alpha[(k_prime,0,L)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,0,L)))\n",
    "            \n",
    "    # Set objective\n",
    "    \n",
    "    m.setObjective( sum( loss[n] \n",
    "                        + sum( λ[(n,k_prime,0,L)]*g[(n,k_prime,0,L)] for k_prime in range(K))\n",
    "                       for n in range(N)) ,GRB.MINIMIZE)\n",
    "    \n",
    "    # Add constraints\n",
    "    \n",
    "    for n in range(N):\n",
    "        m.addConstr(sum(z[(n,k_prime,0,L)] for k_prime in range(K)) + beta[(0,L)] \n",
    "                    <= ((K*w_ub)+b_ub + epsilon)*y_hat[n], name=\"C1 Binary Neuron \"+str((n,0,L))) \n",
    "\n",
    "        m.addConstr(sum(z[(n,k_prime,0,L)] for k_prime in range(K)) + beta[(0,L)] \n",
    "                    >= epsilon + ((K*w_lb)+b_lb - epsilon)*(1-y_hat[n]), name=\"C2 Binary Neuron \"+str((n,0,L)))\n",
    "        \n",
    "        m.addConstr(loss[n] >= y[n] - y_hat[n], name = \"C1 Loss Function\"+str(n))\n",
    "        m.addConstr(loss[n] >= -y[n] + y_hat[n], name = \"C2 Loss Function\"+str(n))\n",
    "        \n",
    "        for k_prime in range(K):\n",
    "            m.addConstr(z[(n,k_prime,0,L)] <= alpha[(k_prime,0,L)]+ w_ub*(1-g[(n,k_prime,0,L)]),\n",
    "                        name=\"z-alpha Upper Bound \"+str((n,k_prime,0,L)))\n",
    "            m.addConstr(z[(n,k_prime,0,L)] - alpha[(k_prime,0,L)] >= (-w_ub)*(1-g[(n,k_prime,0,L)]), \n",
    "                            name=\"z-alpha Lower Bound\"+str((n,k_prime,0,L)))\n",
    "            m.addConstr(z[(n,k_prime,0,L)] <= (w_ub)*g[(n,k_prime,0,L)], name = \"z-g Upper Bound\"+str((n,k_prime,0,L)))\n",
    "            m.addConstr(z[(n,k_prime,0,L)] >= (w_lb)*g[(n,k_prime,0,L)], name = \"z-g Lower Bound\"+str((n,k_prime,0,L)))\n",
    "                            \n",
    "    # Optimize\n",
    "    \n",
    "    m.setParam('OutputFlag', 0) # uncomment to silence the output\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "            \n",
    "    for v in m.getVars():\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output[v.varName] = v.x \n",
    "\n",
    "#     print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    return(m.objVal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd94b2",
   "metadata": {},
   "source": [
    "### Solving the dual with the Subgradient algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7a1e11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2021-07-16\n",
      "Using license file /Library/gurobi911/gurobi.lic\n",
      "Iteration count: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# λ_norm_tracker = []\n",
    "# for i in range(100):\n",
    "\n",
    "    ## initialize langrange multiplier\n",
    "\n",
    "λ = {} \n",
    "\n",
    "np.random.seed(6)\n",
    "\n",
    "for n in range(N):\n",
    "    for k_prime in range(K):\n",
    "        for k in range(K):\n",
    "            for l in range(1,L):\n",
    "                λ[(n,k_prime,k,l)] = np.random.uniform(low=-100, high=100)\n",
    "        λ[(n,k_prime,0,L)] = np.random.uniform(low=-100, high=100)\n",
    "\n",
    "λ_array = list(λ.values())        \n",
    "\n",
    "output = {} # dictionary of outputs\n",
    "\n",
    "    ## Solve subproblems and find the dual objective\n",
    "\n",
    "dual_obj = zeta_0(λ) + sum(zeta_l(l,λ) for l in range(1,L-1)) + zeta_penultimate_L(λ) + zeta_L(λ) \n",
    "\n",
    "    ## Find the subgradient vector at λ\n",
    "\n",
    "s = {}\n",
    "\n",
    "for n in range(N):\n",
    "    for k_prime in range(K):\n",
    "        for k in range(K):\n",
    "            for l in range(1,L):\n",
    "                s[(n,k_prime,k,l)] = output['g'+str((n,k_prime,k,l))] - output['h'+str((n,k_prime,l-1))]\n",
    "        s[(n,k_prime,0,L)] = output['g'+str((n,k_prime,0,L))] - output['h'+str((n,k_prime,L-1))]\n",
    "\n",
    "s_array = np.array(list(s.values()))\n",
    "\n",
    "    ## Simple Stepsize\n",
    "\n",
    "# gamma = 1\n",
    "\n",
    "    ## Adaptive Stepsize\n",
    "\n",
    "mu_naught = 2\n",
    "mu = mu_naught\n",
    "\n",
    "Z_best = 0 # Lower bound on primal\n",
    "\n",
    "gamma = mu*((Z_best - dual_obj)/(np.linalg.norm(s_array))**2)\n",
    "\n",
    "    ## Track the projected subgradinet\n",
    "\n",
    "indicator = []\n",
    "\n",
    "for i in range(len(λ_array)):\n",
    "    if (λ_array[i] + gamma*s_array[i]) > 0:\n",
    "        indicator.append(1)\n",
    "    else:\n",
    "        indicator.append(0)\n",
    "\n",
    "indicator = np.array(indicator)\n",
    "projected_s = indicator.T*s_array\n",
    "\n",
    "#     if (dual_obj >= -1e-6) and (dual_obj_tracker[t]-dual_obj_tracker[t-1] < 1e-6):\n",
    "#         print(\"The dual objective roughly optimal\")\n",
    "#     else:\n",
    "#         print(\"Proceed with the subgradient algorithm\")\n",
    "\n",
    "subgradient_tracker = [np.linalg.norm(s_array)]\n",
    "dual_obj_tracker = [dual_obj]\n",
    "gamma_tracker = [gamma]\n",
    "projected_s_tracker = [np.linalg.norm(projected_s)]\n",
    "mu_tracker = [mu]\n",
    "\n",
    "adapt_param_factor = 2/3 # try 1/4 and 2/3\n",
    "\n",
    "T = 0 # Number of times Z_{D} did not increase\n",
    "\n",
    "\n",
    "for t in range(1,1000): \n",
    "\n",
    "    if t%100 == 0:\n",
    "        print(\"Iteration count:\", t)\n",
    "\n",
    "        ## Update λ\n",
    "\n",
    "    for n in range(N):\n",
    "        for k_prime in range(K):\n",
    "            for k in range(K):\n",
    "                for l in range(1,L):\n",
    "                    λ[(n,k_prime,k,l)] = λ[(n,k_prime,k,l)] + gamma*s[(n,k_prime,k,l)]\n",
    "            λ[(n,k_prime,0,L)] = λ[(n,k_prime,0,L)] + gamma*s[(n,k_prime,0,L)]\n",
    "\n",
    "    λ_array = np.array(list(λ.values()))\n",
    "\n",
    "        ## Solve subproblems and find the dual objective\n",
    "\n",
    "    dual_obj = zeta_0(λ) + sum(zeta_l(l,λ) for l in range(1,L-1)) + zeta_penultimate_L(λ) + zeta_L(λ) \n",
    "\n",
    "    dual_obj_tracker.append(dual_obj)\n",
    "\n",
    "        ## Find the subgradient vector at λ\n",
    "\n",
    "    for n in range(N):\n",
    "        for k_prime in range(K):\n",
    "            for k in range(K):\n",
    "                for l in range(1,L):\n",
    "                    s[(n,k_prime,k,l)] = output['g'+str((n,k_prime,k,l))] - output['h'+str((n,k_prime,l-1))]\n",
    "            s[(n,k_prime,0,L)] = output['g'+str((n,k_prime,0,L))] - output['h'+str((n,k_prime,L-1))]\n",
    "\n",
    "    s_array = np.array(list(s.values()))\n",
    "    subgradient_tracker.append(np.linalg.norm(s_array))\n",
    "\n",
    "        ## Simple step-size\n",
    "\n",
    "#     gamma = 1/np.sqrt(t) \n",
    "\n",
    "        ## Adaptive Polyak Stepsize\n",
    "\n",
    "    if dual_obj > Z_best:\n",
    "        Z_best = dual_obj\n",
    "\n",
    "    if not (dual_obj > dual_obj_tracker[-2]):\n",
    "        T += 1\n",
    "    else:\n",
    "        T = 0\n",
    "\n",
    "    if T >= 2: # scaling mu if Z_{D} did not increase in the last 2 iterations\n",
    "        mu = adapt_param_factor*mu\n",
    "\n",
    "    mu_tracker.append(mu)\n",
    "\n",
    "    gamma = mu*((Z_best - dual_obj)/(np.linalg.norm(s_array))**2)\n",
    "    gamma_tracker.append(gamma)\n",
    "\n",
    "        ## Track norm of projected subgradinet\n",
    "\n",
    "    indicator = []\n",
    "\n",
    "    for i in range(len(λ_array)):\n",
    "        if (λ_array[i] + gamma*s_array[i]) < 0:\n",
    "            indicator.append(0)\n",
    "        else:\n",
    "            indicator.append(1)\n",
    "\n",
    "    indicator = np.array(indicator)\n",
    "    projected_s = indicator.T*s_array\n",
    "\n",
    "    projected_s_tracker.append(np.linalg.norm(projected_s))\n",
    "\n",
    "    if (dual_obj >= -1e-5) and (dual_obj_tracker[t]-dual_obj_tracker[t-1] < 1e-6):\n",
    "        break\n",
    "\n",
    "#         The lower bound on the primal might not always be 0, but should be??\n",
    "\n",
    "# assert all((x <= 1e-8 and x >= -1e-8) for x in λ_array*s_array), \"Complementary Slackness Conditions are not upheld\"\n",
    "\n",
    "#     λ_norm_tracker.append(np.linalg.norm(λ_array))\n",
    "    \n",
    "# λ_norm_tracker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4b944",
   "metadata": {},
   "source": [
    "###  Plot Dual Objective and Subgradient figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10c1857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "fig.set_size_inches(12, 12)\n",
    "\n",
    "subgrad_y1 = [np.mean(subgradient_tracker[i:i+10]) for i in range(0,len(subgradient_tracker),10)]\n",
    "# subgrad_y2 = [np.mean(projected_s_tracker[i:i+10]) for i in range(0,len(projected_s_tracker),10)]\n",
    "\n",
    "ax1.plot([x for x in range(t+1)], dual_obj_tracker, c=\"dodgerblue\")\n",
    "ax2.plot([x for x in range(len(subgrad_y1))], subgrad_y1, c=\"indianred\")\n",
    "# ax2.plot([x for x in range(len(projected_s_tracker))], projected_s_tracker, c=\"dodgerblue\")\n",
    "\n",
    "ax1.set_title(\"Dual Objective (μ0 = {}, α = {})\".format(np.round(mu_naught,2), np.round(adapt_param_factor,2)), fontsize=14)\n",
    "ax2.set_title(\"10-Norm-of-Subgradient Averages (μ0 = {}, α = {})\".format(np.round(mu_naught,2), np.round(adapt_param_factor,2)), fontsize=14)\n",
    "\n",
    "ax2.legend([\"Subgradient\", \"Projected Subgradient\"])\n",
    "\n",
    "ax1.set_xlabel('Iteration Count', fontsize=14)\n",
    "ax2.set_xlabel('Time Averaged-Counts', fontsize=14)\n",
    "\n",
    "# filename = 'mu0={} alpha={}.png'.format(np.round(mu_naught,2), np.round(adapt_param_factor,2))\n",
    "# plt.savefig(\"Subgradient Plots/\"+filename)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b5bec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.251000245666859e-06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bf7f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # z-g-h-λ Table Maker\n",
    "\n",
    "# index_list = []\n",
    "# z_list = []\n",
    "# g_list = []\n",
    "# h_list = []\n",
    "# λ_list = []\n",
    "\n",
    "# for n in range(N):\n",
    "#     for k_prime in range(K):\n",
    "#         for k in range(K):\n",
    "#             for l in range(1,L):\n",
    "#                 index_list.append((n,k_prime,k,l))\n",
    "#                 z_list.append(output['z'+str((n,k_prime,k,l))])\n",
    "#                 g_list.append(output['g'+str((n,k_prime,k,l))])\n",
    "#                 h_list.append(output['h'+str((n,k_prime,l-1))])\n",
    "#                 λ_list.append(λ[(n,k_prime,k,l)])\n",
    "                \n",
    "#         index_list.append((n,k_prime,0,L))\n",
    "#         z_list.append(output['z'+str((n,k_prime,0,L))])\n",
    "#         g_list.append(output['g'+str((n,k_prime,0,L))])\n",
    "#         h_list.append(output['h'+str((n,k_prime,L-1))])\n",
    "#         λ_list.append(λ[(n,k_prime,0,L)])\n",
    "        \n",
    "# z_g_h_λ_dict = {\"(n,k\\',k,l)\":index_list, \"z-values\": z_list, \"g-values\": g_list, \"h-values\": h_list, \"λ\":λ_list}                \n",
    "# df = pd.DataFrame(z_g_h_λ_dict)\n",
    "# # df.to_csv(\"z-g-h-λ Table.csv\") \n",
    "# df\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7933d567",
   "metadata": {},
   "source": [
    "### Primal Feasible Solution w/SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4621e0b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 38.51457977294922\n",
      "500 0.2862238883972168\n",
      "1000 0.23746521770954132\n",
      "1500 0.22633832693099976\n",
      "2000 0.18645845353603363\n",
      "2500 4.172925400780514e-06\n",
      "Function after training:\n",
      "f(0,0) = tensor([[1.6689e-06]], grad_fn=<AddmmBackward>)\n",
      "f(0,1) = tensor([[1.0000]], grad_fn=<AddmmBackward>)\n",
      "f(1,0) = tensor([[1.0000]], grad_fn=<AddmmBackward>)\n",
      "f(1,1) = tensor([[5.9605e-07]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Referred to https://gist.github.com/RichardKelley/17ef5f2291c273de11540c33dc1bfbf2\n",
    "# to build the Pytorch nn\n",
    "# @RichardKelley\n",
    "\n",
    "torch.manual_seed(93)\n",
    "\n",
    "class XorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Linear(2,2)\n",
    "        self.layer1 = nn.Linear(2,2)\n",
    "        self.layer2 = nn.Linear(2,2)\n",
    "        self.layer3 = nn.Linear(2,1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer0(x))\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "m = XorNet()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(m.parameters(), lr=1e-3)\n",
    "\n",
    "training_epochs = 3000\n",
    "minibatch_size = 32\n",
    "\n",
    "# input-output pairs\n",
    "pairs = [(np.asarray([0.0,0.0]), [0.0]),\n",
    "         (np.asarray([0.0,1.0]), [1.0]),\n",
    "         (np.asarray([1.0,0.0]), [1.0]),\n",
    "         (np.asarray([1.0,1.0]), [0.0])]\n",
    "\n",
    "state_matrix = np.vstack([x[0] for x in pairs])\n",
    "label_matrix = np.vstack([x[1] for x in pairs])\n",
    "\n",
    "# initialize weights from our dual pre-training\n",
    "\n",
    "for k in range(K):\n",
    "    for d in range(D):\n",
    "        m.layer0.weight.data[k][d] = output['alpha'+str((d,k,0))]\n",
    "    m.layer0.bias.data[k] = output['beta'+str((k,0))]\n",
    "\n",
    "m.layer0.load_state_dict(m.layer0.state_dict())    \n",
    "    \n",
    "for k in range(K):\n",
    "    for k_prime in range(K):\n",
    "        m.layer1.weight.data[k][k_prime] = output['alpha'+str((k_prime,k,1))]\n",
    "    m.layer1.bias.data[k] = output['beta'+str((k,1))]\n",
    "\n",
    "m.layer1.load_state_dict(m.layer1.state_dict())    \n",
    "    \n",
    "for k in range(K):\n",
    "    for k_prime in range(K):\n",
    "        m.layer2.weight.data[k][k_prime] = output['alpha'+str((k_prime,k,2))]\n",
    "    m.layer2.bias.data[k] = output['beta'+str((k,2))]\n",
    "\n",
    "m.layer2.load_state_dict(m.layer2.state_dict())\n",
    "        \n",
    "for k_prime in range(K):\n",
    "    m.layer3.weight.data[0][k_prime] = output['alpha'+str((k_prime,0,3))]\n",
    "m.layer3.bias.data[0] = output['beta'+str((0,3))]    \n",
    "\n",
    "m.layer3.load_state_dict(m.layer3.state_dict())\n",
    "\n",
    "for i in range(training_epochs):\n",
    "        \n",
    "    for batch_ind in range(4):\n",
    "        # wrap the data in variables\n",
    "        minibatch_state_var = Variable(torch.Tensor(state_matrix))\n",
    "        minibatch_label_var = Variable(torch.Tensor(label_matrix))\n",
    "                \n",
    "        # forward pass\n",
    "        y_pred = m(minibatch_state_var)\n",
    "        \n",
    "        # compute and print loss\n",
    "        loss = loss_fn(y_pred, minibatch_label_var)\n",
    "        \n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backwards pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # step the optimizer - update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print(i, loss.item())\n",
    "        \n",
    "print(\"Function after training:\")\n",
    "print(\"f(0,0) = {}\".format(m(Variable(torch.Tensor([0.0,0.0]).unsqueeze(0)))))\n",
    "print(\"f(0,1) = {}\".format(m(Variable(torch.Tensor([0.0,1.0]).unsqueeze(0)))))\n",
    "print(\"f(1,0) = {}\".format(m(Variable(torch.Tensor([1.0,0.0]).unsqueeze(0)))))\n",
    "print(\"f(1,1) = {}\".format(m(Variable(torch.Tensor([1.0,1.0]).unsqueeze(0)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb819d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.1016,  1.1016],\n",
       "         [-1.0000,  0.4988]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.1721, -0.5012], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.7970,  0.6775],\n",
       "         [-0.8650,  0.6828]], requires_grad=True), Parameter containing:\n",
       " tensor([-1.0941,  1.1017], requires_grad=True), Parameter containing:\n",
       " tensor([[ 1.2064,  1.0116],\n",
       "         [-1.0000, -1.0000]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.4968, -1.0000], requires_grad=True), Parameter containing:\n",
       " tensor([[-1.0374,  1.0000]], requires_grad=True), Parameter containing:\n",
       " tensor([1.5154], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = list(m.parameters())\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e02532fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.]) :  tensor([1.6689e-06])\n",
      "tensor([0., 1.]) :  tensor([1.0000])\n",
      "tensor([1., 0.]) :  tensor([1.0000])\n",
      "tensor([1., 1.]) :  tensor([5.9605e-07])\n",
      "\n",
      "Prediction Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = torch.Tensor([0,1,1,0]).view(-1,1)\n",
    "\n",
    "correct_pred = 0\n",
    "for n in range(N):\n",
    "    h0 = torch.matmul(model_params[0].data, X[n]) + model_params[1].data\n",
    "    h0[h0 <= 0] = 0\n",
    "#     h0[h0 > 0] = 1\n",
    "    \n",
    "    h1 = torch.matmul(model_params[2].data, h0) + model_params[3].data\n",
    "    h1[h1 <= 0] = 0\n",
    "#     h1[h1 > 0] = 1\n",
    "    \n",
    "    h2 = torch.matmul(model_params[4].data, h1) + model_params[5].data\n",
    "    h2[h2 <= 0] = 0\n",
    "#     h2[h2 > 0] = 1\n",
    "    \n",
    "    y_hat = torch.matmul(model_params[6].data, h2) + model_params[7].data\n",
    "    y_hat[y_hat <= 0] = 0\n",
    "#     y_hat[y_hat > 0] = 1\n",
    "    \n",
    "    if np.round(y_hat[0],1) == Y[n].item():\n",
    "        correct_pred += 1\n",
    "    \n",
    "    print(X[n], \": \", y_hat)\n",
    "\n",
    "print(\"\\nPrediction Accuracy = \", correct_pred/(N)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3c618",
   "metadata": {},
   "source": [
    "### Primal Feasible Solution w/MIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f24d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiLayerMIPOptimizer(init_weights): \n",
    "        \n",
    "    # Create a new model\n",
    "    m = gp.Model(\"MIP-NN\")\n",
    "\n",
    "    # Create variables\n",
    "    \n",
    "    alpha = {}\n",
    "    beta = {}\n",
    "    h = {}\n",
    "    h = {}\n",
    "    z = {}\n",
    "    y_hat = {}\n",
    "    loss = {}\n",
    "\n",
    "    for k in range(K):\n",
    "        alpha[k,0,L] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k,0,L))) \n",
    "\n",
    "        for d in range(D):\n",
    "            alpha[(d,k,0)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((d,k,0))) \n",
    "        for k_prime in range(K):\n",
    "            for l in range(1,L):\n",
    "                alpha[(k_prime,k,l)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name=\"alpha\"+str((k_prime,k,l))) \n",
    "    \n",
    "        for l in range(0,L):\n",
    "            beta[(k,l)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((k,l))) \n",
    "    \n",
    "    beta[(0,L)] = m.addVar(lb=b_lb, ub=b_ub, vtype=GRB.CONTINUOUS, name=\"beta\"+str((0,L)))\n",
    "    \n",
    "    for n in range(N):\n",
    "\n",
    "        y_hat[n] = m.addVar(vtype=GRB.BINARY, name=\"y_hat\"+str(n))\n",
    "        loss[n] = m.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=\"loss\"+str(n)) \n",
    "        \n",
    "        for k in range(K):\n",
    "            for l in range(0,L):\n",
    "                h[(n,k,l)] = m.addVar(vtype=GRB.BINARY, name=\"h\"+str((n,k,l))) \n",
    "            for k_prime in range(K):\n",
    "                for l in range(1,L):\n",
    "                    z[(n,k_prime,k,l)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name= \"z\"+str((n,k_prime,k,l))) \n",
    "        \n",
    "            z[(n,k,0,L)] = m.addVar(lb=w_lb, ub=w_ub, vtype=GRB.CONTINUOUS, name= \"z\"+str((n,k,0,L)))\n",
    "                        \n",
    "    # Set objective\n",
    "    m.setObjective(sum(loss[n] for n in range(N)), GRB.MINIMIZE)\n",
    "\n",
    "    # Add constraints\n",
    "        \n",
    "    for n in range(N):\n",
    "        m.addConstr(sum(z[(n,k_prime,0,L)] for k_prime in range(K)) + beta[(0,L)] \n",
    "                    <= ((K*w_ub)+b_ub + epsilon)*y_hat[n], name=\"C1 Binary Neuron \"+str((n,0,L))) \n",
    "\n",
    "        m.addConstr(sum(z[(n,k_prime,0,L)] for k_prime in range(K)) + beta[(0,L)] \n",
    "                    >= epsilon + ((K*w_lb)+b_lb - epsilon)*(1-y_hat[n]), name=\"C2 Binary Neuron \"+str((n,0,L)))\n",
    "        \n",
    "        m.addConstr(loss[n] >= y[n] - y_hat[n], name = \"C1 Loss Function\"+str(n))\n",
    "        m.addConstr(loss[n] >= -y[n] + y_hat[n], name = \"C2 Loss Function\"+str(n))\n",
    "        \n",
    "        for k in range(K):\n",
    "            m.addConstr(sum(alpha[(d,k,0)]*x[n,d] for d in range(D)) + beta[(k,0)] \n",
    "                        <= (D*w_ub+b_ub + epsilon)*h[(n,k,0)], name=\"C1 Binary Neuron \"+str((n,k,0)))\n",
    "            \n",
    "            m.addConstr(sum(alpha[(d,k,0)]*x[n,d] for d in range(D)) + beta[(k,0)] \n",
    "                        >= epsilon + (D*w_lb+b_lb - epsilon)*(1-h[(n,k,0)]), name=\"C2 Binary Neuron \"+str((n,k,0)))\n",
    "\n",
    "            for l in range(1, L):\n",
    "                m.addConstr(sum(z[(n,k_prime,k,l)] for k_prime in range(K)) + beta[(k,l)] \n",
    "                            <= (K*w_ub+b_ub + epsilon)*h[(n,k,l)], name=\"C1 Binary Neuron \"+str((n,k,l))) \n",
    "                \n",
    "                # 0 NOT <= -0.01 \n",
    "                \n",
    "                m.addConstr(sum(z[(n,k_prime,k,l)] for k_prime in range(K)) + beta[(k,l)] \n",
    "                            >= epsilon + (K*w_lb+b_lb - epsilon)*(1-h[(n,k,l)]), name=\"C2 Binary Neuron \"+str((n,k,l)))\n",
    "                \n",
    "        for k_prime in range(K):\n",
    "            for k in range(K):\n",
    "                for l in range(1,L):\n",
    "                    m.addConstr(z[(n,k_prime,k,l)] <= alpha[(k_prime,k,l)] + (w_ub-w_lb)*(1.0-h[(n,k_prime,l-1)]), name=\"Explicit z-alpha Bound \"+str((n,k_prime,k,l))) \n",
    "                    m.addConstr(z[(n,k_prime,k,l)] >= alpha[(k_prime,k,l)] + (w_lb-w_ub)*(1.0-h[(n,k_prime,l-1)]), name=\"z-alpha Bound \"+str((n,k_prime,k,l))) \n",
    "                    m.addConstr(z[(n,k_prime,k,l)] <= (w_ub)*h[(n,k_prime,l-1)], name=\"z-0 Bound1 \"+str((n,k,k_prime,l)))\n",
    "                    m.addConstr(z[(n,k_prime,k,l)] >= (w_lb)*h[(n,k_prime,l-1)], name=\"z-0 Bound2 \"+str((n,k,k_prime,l)))\n",
    "\n",
    "            m.addConstr(z[(n,k_prime,0,L)] <= alpha[(k_prime,0,L)] + (w_ub-w_lb)*(1.0-h[(n,k_prime,L-1)]), name=\"Explicit z-alpha Bound \"+str((n,k_prime,0,L))) \n",
    "            m.addConstr(z[(n,k_prime,0,L)] >= alpha[(k_prime,0,L)] + (w_lb-w_ub)*(1.0-h[(n,k_prime,L-1)]), name=\"z-alpha Bound \"+str((n,k_prime,0,L))) \n",
    "            m.addConstr(z[(n,k_prime,0,L)] <= (w_ub)*h[(n,k_prime,L-1)], name=\"z-0 Bound1 \"+str((n,k_prime,0,L)))\n",
    "            m.addConstr(z[(n,k_prime,0,L)] >= (w_lb)*h[(n,k_prime,L-1)], name=\"z-0 Bound2 \"+str((n,k_prime,0,L)))\n",
    "\n",
    "    # Fix alphas and betas to check feasibility            \n",
    "            \n",
    "#     for k in range(K):\n",
    "#         m.addConstr(alpha[k,0,L] == init_weights['alpha'+str((k,0,L))], name=\"strict1\"+str((k,0,L)))\n",
    "\n",
    "#         for d in range(D):\n",
    "#             m.addConstr(alpha[(d,k,0)] == init_weights['alpha'+str((d,k,0))], name=\"strict2\"+str((d,k,0)))\n",
    "#         for k_prime in range(K):\n",
    "#             for l in range(1,L):\n",
    "#                 m.addConstr(alpha[(k_prime,k,l)] == init_weights['alpha'+str((k_prime,k,l))], name=\"strict3\"+str((k_prime,k,l)))\n",
    "    \n",
    "#         for l in range(0,L):\n",
    "#             m.addConstr(beta[(k,l)] == init_weights['beta'+str((k,l))], name=\"strict4\"+str((k,l)))\n",
    "    \n",
    "#     m.addConstr(beta[(0,L)] == init_weights['beta'+str((0,L))], name=\"strict5\")\n",
    "            \n",
    "    # Set initial feasible solution\n",
    "    \n",
    "    for k in range(K):\n",
    "        alpha[k,0,L].start = init_weights['alpha'+str((k,0,L))]\n",
    "\n",
    "        for d in range(D):\n",
    "            alpha[(d,k,0)].start = init_weights['alpha'+str((d,k,0))]\n",
    "        for k_prime in range(K):\n",
    "            for l in range(1,L):\n",
    "                alpha[(k_prime,k,l)].start = init_weights['alpha'+str((k_prime,k,l))]\n",
    "    \n",
    "        for l in range(0,L):\n",
    "            beta[(k,l)].start = init_weights['beta'+str((k,l))]\n",
    "    \n",
    "    beta[(0,L)].start = init_weights['beta'+str((0,L))]\n",
    "    \n",
    "    # Optimize model\n",
    "#     m.setParam('OutputFlag', 0)\n",
    "    m.optimize()\n",
    "    m.printQuality()\n",
    "\n",
    "    output_dict = {}\n",
    "    \n",
    "    for v in m.getVars():\n",
    "#         print('%s %s %g' % (v.varName, \"=\", np.round(v.x, 3)))\n",
    "        output_dict[v.varName] = np.round(v.x, 3)\n",
    "\n",
    "    print('Obj: %g' % m.objVal)\n",
    "    \n",
    "    model_params = []\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for k in range(K):\n",
    "        weights.append([output_dict['alpha'+str((d,k,0))] for d in range(D)])\n",
    "        biases.append(output_dict['beta'+str((k,0))])\n",
    "    model_params.append(np.array(weights))\n",
    "    model_params.append(np.array(biases))\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        for k in range(K):\n",
    "            weights.append([output_dict['alpha'+str((k_prime,k,l))] for k_prime in range(K)])\n",
    "            biases.append(output_dict['beta'+str((k,l))])\n",
    "        model_params.append(np.array(weights))\n",
    "        model_params.append(np.array(biases))\n",
    "    \n",
    "    weights = [output_dict['alpha'+str((k_prime,0,L))] for k_prime in range(K)]\n",
    "    biases = [output_dict['beta'+str((0,L))]]\n",
    "    model_params.append(np.array(weights))\n",
    "    model_params.append(np.array(biases))\n",
    "    \n",
    "    return(output_dict, model_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beed52ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (mac64)\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 224 rows, 93 columns and 624 nonzeros\n",
      "Model fingerprint: 0xa7ab08d9\n",
      "Variable types: 65 continuous, 28 integer (28 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+00]\n",
      "\n",
      "User MIP start produced solution with objective 2 (0.02s)\n",
      "Loaded user MIP start with objective 2\n",
      "\n",
      "Presolve removed 8 rows and 4 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 216 rows, 89 columns, 608 nonzeros\n",
      "Variable types: 61 continuous, 28 integer (28 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 47 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0    4    2.00000    0.00000   100%     -    0s\n",
      "H    0     0                       0.0000000    0.00000  0.00%     -    0s\n",
      "     0     0    0.00000    0    4    0.00000    0.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (47 simplex iterations) in 0.07 seconds\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 2: 0 2 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "\n",
      "Solution quality statistics for model MIP-NN :\n",
      "  Maximum violation:\n",
      "    Bound       : 0.00000000e+00\n",
      "    Constraint  : 5.32907052e-15 (C2 Binary Neuron (1, 0, 0))\n",
      "    Integrality : 0.00000000e+00\n",
      "Obj: 0\n"
     ]
    }
   ],
   "source": [
    "MIP_Var_dict, MIP_model_params = MultiLayerMIPOptimizer(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "700f95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.,  1.],\n",
       "        [ 1., -1.]]), array([-0.99, -0.99]), array([[-1., -1.],\n",
       "        [-1., -1.]]), array([ 1., -1.]), array([[-1., -1.],\n",
       "        [-1., -1.]]), array([1.  , 0.01]), array([1., 1.]), array([-1.])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIP_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1271f797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] :  [0.]\n",
      "[0 1] :  [1.]\n",
      "[1 0] :  [1.]\n",
      "[1 1] :  [0.]\n",
      "\n",
      "Prediction Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "correct_pred = 0\n",
    "for n in range(N):\n",
    "    h0 = np.dot(MIP_model_params[0].data, X[n]) + MIP_model_params[1].data\n",
    "    h0[h0 <= 0] = 0\n",
    "    h0[h0 > 0] = 1\n",
    "    \n",
    "    h1 = np.dot(MIP_model_params[2].data, h0) + MIP_model_params[3].data\n",
    "    h1[h1 <= 0] = 0\n",
    "    h1[h1 > 0] = 1\n",
    "    \n",
    "    h2 = np.dot(MIP_model_params[4].data, h1) + MIP_model_params[5].data\n",
    "    h2[h2 <= 0] = 0\n",
    "    h2[h2 > 0] = 1\n",
    "    \n",
    "    y_hat = np.dot(MIP_model_params[6].data, h2) + MIP_model_params[7].data\n",
    "    y_hat[y_hat <= 0] = 0\n",
    "    y_hat[y_hat > 0] = 1\n",
    "    \n",
    "    if y_hat[0] == Y[n].item():\n",
    "        correct_pred += 1\n",
    "    \n",
    "    print(x[n], \": \", y_hat)\n",
    "\n",
    "print(\"\\nPrediction Accuracy = \", correct_pred/(N)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a0110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379066c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3ec3f4",
   "metadata": {},
   "source": [
    "### Evaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d97d71b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XOR 0 = 0.0 Should be  0.0\n",
      "0 XOR 1 = 0.0 Should be  1.0\n",
      "1 XOR 0 = 0.0 Should be  1.0\n",
      "1 XOR 1 = 0.0 Should be  0.0\n",
      "\n",
      "Prediction Accuracy =  50.0 %\n"
     ]
    }
   ],
   "source": [
    "h = {} # tracks output of units\n",
    "\n",
    "correct_pred = 0\n",
    "\n",
    "for n in range(N):\n",
    "    for k in range(K):\n",
    "        h[(k,0)] = sum(output[\"alpha\"+str((d,k,0))]*x[n,d] for d in range(D)) + output[\"beta\"+str((k,0))]\n",
    "#         print(\"Pre-activated  h[\",(n,k,0),\"] = \", h[(k,0)])\n",
    "\n",
    "        if h[(k,0)] <= 0:\n",
    "            h[(k,0)] = 0\n",
    "        else:\n",
    "            h[(k,0)] = 1\n",
    "#         print(\"h[\",(n,k,0),\"] = \", h[(k,0)])\n",
    "\n",
    "    for l in range(1,L):\n",
    "        for k in range(K):\n",
    "            h[(k,l)] = sum(output[\"alpha\"+str((k_prime,k,l))]*h[(k_prime,l-1)] for k_prime in range(K)) + output[\"beta\"+str((k,l))]\n",
    "#             print(\"Pre-activated h[\",(n,k,l),\"] = \", h[(k,l)])\n",
    "\n",
    "            if h[(k,l)] <= 0:\n",
    "                h[(k,l)] = 0\n",
    "            else:\n",
    "                h[(k,l)] = 1\n",
    "#             print(\"h[\",(n,k,l),\"] = \", h[(k,l)])\n",
    "\n",
    "    y_hat = sum(output[\"alpha\"+str((k_prime,0,L))]*h[(k_prime,L-1)] for k_prime in range(K)) + output[\"beta\"+str((0,L))]\n",
    "    if y_hat <= 0:\n",
    "        y_hat = 0\n",
    "    else:\n",
    "        y_hat = 1\n",
    "\n",
    "    if y_hat == y[n]:\n",
    "        correct_pred += 1\n",
    "    \n",
    "    print(x[n][0], \"XOR\", x[n][1], \"=\", float(y_hat), \"Should be \", float(y[n]))\n",
    "\n",
    "print(\"\\nPrediction Accuracy = \", correct_pred/(n+1)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c234c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3de6c1de",
   "metadata": {},
   "source": [
    "### Notes and Questions (15th June 2021)\n",
    "\n",
    "* TODO for next week:\n",
    "\n",
    "    * Find primal solution using the dual coefficients as initialized values for standard SGD (PyTorch) and our general MIP.\n",
    "        * Some initial start values make the output of a unit 0. So we're in a situation where $ 0 <= -\\epsilon $, which is infeasible. See seed=5\n",
    "        * Removed the $ -\\epsilon $ from constraint $ \\displaystyle  \\sum_{k\\prime=0}^{K} (z_{n,k\\prime,k,l}) + \\beta_{k,l} \\le -\\epsilon + (M+\\epsilon)h_{n,k,l} $ and all similar constraints to fix this \n",
    "        * **But verify with Prof. Mintz**<br><br>\n",
    "        * For SGD, it looks like the initialized values don't always start at a place where we converge to a 0 loss. Depends on the seed (as is the case with SGD in general) \n",
    "        * **Seed 6 is working as a paradigm**\n",
    "<br><br>        \n",
    "    * Reformulate MIP and Relaxation for MNIST and find the results of the primal for SGD and the general MIP. \n",
    "        * MNIST loss function: take binary output and find difference between expected and predicted. Find max of the values in the difference; If even one of the values in the difference is 1, then we have a loss of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd49625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
